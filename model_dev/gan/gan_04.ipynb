{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load Dependencies\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, shutil, time\n",
    "#from importlib import reload\n",
    "from imp import reload\n",
    "#import collections, itertools\n",
    "import unittest\n",
    "#from trainer import unittest\n",
    "#from . import unittest\n",
    "#import trainer.unittest as unittest\n",
    "#from IPython.display import display, HTML\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# Helper libraries\n",
    "from trainer import utils#, vocabulary, tf_embed_viz\n",
    "#import utils\n",
    "#import trainer.utils as utils\n",
    "\n",
    "# rnnlm code\n",
    "from trainer import rnnlm\n",
    "#import trainer.rnnlm as rnnlm\n",
    "#import rnnlm\n",
    "reload(rnnlm)\n",
    "#from trainer import rnnlm_test\n",
    "#import trainer.rnnlm_test as rnnlm_test\n",
    "#reload(rnnlm_test)\n",
    "#from . import rnnlm; reload(rnnlm)\n",
    "#from . import rnnlm_test; reload(rnnlm_test)\n",
    "#import rnnlm; reload(rnnlm)\n",
    "#import rnnlm_test; reload(rnnlm_test)\n",
    "# packages for extracting data\n",
    "import pandas as pd\n",
    "\n",
    "#import cloudstorage as gcs\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_tensorboard(tf_graphdir=\"/tmp/artificial_hotel_reviews/a4_graph\", V=100, H=1024, num_layers=2):\n",
    "    reload(rnnlm)\n",
    "    TF_GRAPHDIR = tf_graphdir\n",
    "    # Clear old log directory.\n",
    "    shutil.rmtree(TF_GRAPHDIR, ignore_errors=True)\n",
    "    \n",
    "    lm = rnnlm.RNNLM(V=V, H=H, num_layers=num_layers)\n",
    "    lm.BuildCoreGraph()\n",
    "    lm.BuildTrainGraph()\n",
    "    lm.BuildSamplerGraph()\n",
    "    summary_writer = tf.summary.FileWriter(TF_GRAPHDIR, lm.graph)\n",
    "    return summary_writer\n",
    "\n",
    "# Unit Tests\n",
    "def test_graph():\n",
    "    reload(rnnlm); reload(rnnlm_test)\n",
    "    utils.run_tests(rnnlm_test, [\"TestRNNLMCore\", \"TestRNNLMTrain\", \"TestRNNLMSampler\"])\n",
    "\n",
    "def test_training():\n",
    "    reload(rnnlm); reload(rnnlm_test)\n",
    "    th = rnnlm_test.RunEpochTester(\"test_toy_model\")\n",
    "    th.setUp(); th.injectCode(run_epoch, score_dataset)\n",
    "    unittest.TextTestRunner(verbosity=2).run(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Training Functions\n",
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=5, learning_rate=None):\n",
    "    assert(learning_rate is not None)\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step0_\n",
    "        use_dropout = True\n",
    "        loss = lm.train_loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "        #### YOUR CODE HERE ####\n",
    "        feed_dict = {lm.input_w_:w,\n",
    "                     lm.target_y_:y,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: use_dropout,\n",
    "                     lm.initial_h_:h}\n",
    "        cost, h, _ = session.run([loss, lm.final_h_, train_op],feed_dict=feed_dict)\n",
    "\n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print(\"[batch {:d}]: seen {:d} words at {:.1f} wps, loss = {:.3f}\".format(\n",
    "                i, total_words, avg_wps, avg_cost))\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_gan_epoch(lm, session, words_to_ids, ids_to_words, train_list, batch_size, verbose=False, tick_s=10, learning_rate=None):\n",
    "    assert(learning_rate is not None)\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "    train_op = lm.train_step_\n",
    "    loss = lm.loss_cnn\n",
    "\n",
    "    #if train:\n",
    "        #train_op = lm.train_step_\n",
    "        #use_dropout = True\n",
    "        ##loss = lm.train_loss_\n",
    "        #loss = lm.loss_cnn\n",
    "    #else:\n",
    "        #train_op = tf.no_op()\n",
    "        #use_dropout = False  # no dropout at test time\n",
    "        #loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "        #loss = lm.loss_cnn\n",
    "\n",
    "    ### UPDATED!!! MUST PASS IN TRAIN_IDS as a list of lists, batch_size\n",
    "    num_samples = 2*batch_size\n",
    "    total_reviews = len(train_list)\n",
    "    num_batches_per_epoch = int((total_reviews-1)/batch_size) + 1\n",
    "    for batch in range(num_batches_per_epoch):\n",
    "        print(\"gan batch: \", batch)\n",
    "        start_index = batch*batch_size\n",
    "        end_index = min((batch+1) * batch_size, total_reviews)\n",
    "        current_training_batch = train_list[start_index:end_index]\n",
    "        #min_review_length = min(len(review) for review in current_training_batch)\n",
    "        min_review_length = 300 #based on the selection criteria when extracting data.  limits learning to ~60 word context\n",
    "        #average_review_length = sum([len(review) for review in current_training_batch])/len(current_training_batch)\n",
    "        #max_steps = 2.0*average_review_length\n",
    "        max_steps = 325\n",
    "        \n",
    "        #for training_review in current_training_batch:\n",
    "        w = np.repeat([[words_to_ids.get('<SOR>')]], num_samples, axis=0)#MUST PASS IN WORDS_TO_IDS\n",
    "        h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "        #can gather all outputs from this loop if you get to it\n",
    "        #get the cell state and timestep 300\n",
    "        h_artificial_300 = None\n",
    "        for i in range(max_steps):\n",
    "            if i == min_review_length:\n",
    "                h_artificial_300 = h[0][1]\n",
    "            h, y = sample_step(lm, session, w[:,-1:], h)\n",
    "            w = np.hstack((w,y))\n",
    "        artificial_review_final_states = []\n",
    "        artificial_review_ids = []\n",
    "        #for row in w:\n",
    "        for a, row in enumerate(h_artificial_300):\n",
    "            #print(\"generated during training\", end=\":  \")\n",
    "            new_artificial_review = []\n",
    "            for b, word_id in enumerate(w[a]):\n",
    "                new_artificial_review.append(word_id)\n",
    "                #print(ids_to_words[word_id], end=\"\")\n",
    "                if (b != 0) and (word_id == words_to_ids.get(\"<EOR>\")):\n",
    "                    break\n",
    "            #print(\"\")\n",
    "            #if len(new_artificial_review) >= 0.75*average_review_length:\n",
    "            if len(new_artificial_review) >= min_review_length:\n",
    "                artificial_review_ids.append(new_artificial_review)\n",
    "                artificial_review_final_states.append(row)\n",
    "        \n",
    "        print(\"generated during training batch \", batch, \":\")\n",
    "        for review in artificial_review_ids[:5]:\n",
    "            for word_id in review:\n",
    "                print(ids_to_words[word_id], end=\"\")\n",
    "            print()\n",
    "        #print(artificial_review_ids[:5])\n",
    "        #now you have current_training_batch and artificial_review_ids\n",
    "        #clip all data to the same length for simplicity\n",
    "        num_reviews = min(len(current_training_batch), len(artificial_review_ids))\n",
    "        print(\"gan batch: \", batch, \" has \", num_reviews, \n",
    "              \" real reviews and \", num_reviews, \" artificial reviews.\")\n",
    "        \n",
    "        if num_reviews == 0:\n",
    "            continue\n",
    "        \n",
    "        current_training_batch = [review[:min_review_length] for review in current_training_batch]\n",
    "        #not sure this is needed\n",
    "        artificial_review_ids = [review[:min_review_length] for review in artificial_review_ids]\n",
    "        \n",
    "        ##get final states for real reviews\n",
    "        #w_training = np.array(current_training_batch)\n",
    "        #h = session.run(lm.initial_h_, {lm.input_w_: w_training})\n",
    "        #feed_dict = {lm.input_w_:w_training,\n",
    "                     #lm.learning_rate_: learning_rate,\n",
    "                     #lm.use_dropout_: False,\n",
    "                     #lm.initial_h_:h}\n",
    "        #h_real = session.run([lm.final_h_],feed_dict=feed_dict)#no training, just get states\n",
    "        \n",
    "        #real_review_final_states = []\n",
    "        #prob don't need to do anything to h_real\n",
    "        #for row in h_real:\n",
    "            #if len(new_artificial_review) >= 300:\n",
    "                #artificial_review_ids.append(new_artificial_review)\n",
    "                #artificial_review_final_states.append(row)\n",
    "                \n",
    "        #now let's even out the number of examples\n",
    "        current_training_batch = current_training_batch[:num_reviews]\n",
    "        artificial_review_ids = artificial_review_ids[:num_reviews]\n",
    "        #print(h_real[0])\n",
    "        ##print(h_real[1])#wtf why won't this work\n",
    "        ##print(h_real[1].shape)\n",
    "        ##h_real = h_real[1][:num_reviews]\n",
    "        #h_real = h_real[:num_reviews]\n",
    "        #print(h_real)\n",
    "        #artificial_review_final_states[:num_reviews]\n",
    "        real_review_list_for_retraining_softmax = current_training_batch[:]\n",
    "        \n",
    "        #label each review and shuffle data\n",
    "        current_training_batch = [(review,[1,0]) for review in current_training_batch]#might need to swap labels\n",
    "        artificial_review_training_batch = [(np.array(review),[0,1]) for review in artificial_review_ids]\n",
    "        #print(current_training_batch[:10])\n",
    "        #print()\n",
    "        #print(artificial_review_ids[:10])\n",
    "        #print()\n",
    "        ##label each review hidden state and shuffle\n",
    "        #training_states = [(review,np.array([0,1])) for review in h_real]#might need to swap labels\n",
    "        #artificial_review_states = [(review,np.array([1,0])) for review in artificial_review_final_states]\n",
    "        \n",
    "        #combine training lists\n",
    "        current_training_batch.extend(artificial_review_training_batch)\n",
    "        np.random.shuffle(current_training_batch)\n",
    "        \n",
    "        #print(current_training_batch[:10])\n",
    "        #print()\n",
    "        #np.random.shuffle(training_states)\n",
    "        #print(training_states)\n",
    "        \n",
    "        #train discriminator\n",
    "        #now unzip into \"w\" and \"y\"\n",
    "        review_list, labels = zip(*current_training_batch)\n",
    "        #review_states, labels = zip(*training_states)\n",
    "        #convert to matrix form\n",
    "        #print(labels)\n",
    "        w = np.array(list(review_list))\n",
    "        #w = np.array(list(review_states))\n",
    "        #y = np.array(list(labels))\n",
    "        y = np.array(labels)\n",
    "        #print(w.shape)\n",
    "        #print(y.shape)\n",
    "        #print()\n",
    "        #batching is done at the review level\n",
    "        #the whole review is fed in at once, so initialize h first\n",
    "        #if batch == 0:\n",
    "        \n",
    "        #train CNN classifier\n",
    "        train_op = lm.train_step_\n",
    "        h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "        #feed_dict = {lm.input_x:w,\n",
    "                     #lm.input_y:y,\n",
    "                     #lm.learning_rate_: learning_rate,\n",
    "                     #lm.use_dropout_: True}\n",
    "        feed_dict = {lm.input_w_: w, \n",
    "                     lm.input_y: y,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: True, \n",
    "                     lm.initial_h_: h}\n",
    "        accuracy, cost, h, _ = session.run([lm.accuracy, loss, lm.final_h_, train_op],feed_dict=feed_dict)\n",
    "        print(\"discriminator training accuracy for gan batch \", batch, \" is: \", accuracy)\n",
    "        print(\"discriminator training cost for gan batch \", batch, \" is: \", cost)\n",
    "        \n",
    "        ##train discriminator on fake reviews\n",
    "        ##now unzip into \"w\" and \"y\"\n",
    "        #review_list, labels = zip(*artificial_review_ids)\n",
    "        #w = np.array(list(review_list))\n",
    "        #y = np.array(labels)\n",
    "        \n",
    "        ##train CNN classifier\n",
    "        #train_op = self.train_step_\n",
    "        #h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "        #feed_dict = {lm.input_w_: w, \n",
    "                     #lm.input_y: y,\n",
    "                     #lm.learning_rate_: learning_rate,\n",
    "                     #lm.use_dropout_: True, \n",
    "                     #lm.initial_h_: h}\n",
    "        #accuracy, cost, h, _ = session.run([lm.accuracy, loss, lm.final_h_, train_op],feed_dict=feed_dict)\n",
    "        #print(\"fake review accuracy for gan batch \", batch, \" is: \", accuracy)\n",
    "        #print(\"fake review cost for gan batch \", batch, \" is: \", cost)\n",
    "        \n",
    "        #train generator\n",
    "        #relabel fake reviews as real\n",
    "        artificial_review_training_batch = [(np.array(review),[1,0]) for review in artificial_review_ids]\n",
    "        #now unzip into \"w\" and \"y\"\n",
    "        review_list, labels = zip(*artificial_review_training_batch)\n",
    "        w = np.array(list(review_list))\n",
    "        y = np.array(labels)\n",
    "        \n",
    "        #train CNN classifier\n",
    "        train_op = lm.train_step1_\n",
    "        h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "        #feed_dict = {lm.input_x:w,\n",
    "                     #lm.input_y:y,\n",
    "                     #lm.learning_rate_: learning_rate,\n",
    "                     #lm.use_dropout_: True}\n",
    "        feed_dict = {lm.input_w_: w, \n",
    "                     lm.input_y: y,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: True, \n",
    "                     lm.initial_h_: h}\n",
    "        accuracy, cost, h, _ = session.run([lm.accuracy, loss, lm.final_h_, train_op],feed_dict=feed_dict)\n",
    "        print(\"generator training accuracy for gan batch \", batch, \" is: \", accuracy)\n",
    "        print(\"generator training cost for gan batch \", batch, \" is: \", cost)\n",
    "        \n",
    "        ##retrain softmax of rnn on real reviews\n",
    "        #flattened_real_ids = np.array([item for sublist in real_review_list_for_retraining_softmax for item in sublist])\n",
    "        ##print(flattened_real_ids[:10])\n",
    "        ##print(flattened_real_ids.shape)\n",
    "        ##print()\n",
    "        #bi = utils.rnnlm_batch_generator(flattened_real_ids, batch_size, max_time=150)\n",
    "        #for i, (w, y) in enumerate(bi):\n",
    "            #cost = 0.0\n",
    "            #if i == 0:\n",
    "                #h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "            #feed_dict = {lm.input_w_: w, \n",
    "                         #lm.target_y_: y, \n",
    "                         #lm.learning_rate_: learning_rate,\n",
    "                         #lm.use_dropout_: False,\n",
    "                         #lm.initial_h_:h}\n",
    "            #cost, h, _ = session.run([lm.train_loss_, lm.final_h_, lm.train_step_softmax_],feed_dict=feed_dict)\n",
    "            #print(\"softmax re-training cost for gan batch \", batch, \" is: \", cost)\n",
    "    \n",
    "    ### UPDATED!!!\n",
    "    total_cost += cost#update\n",
    "    total_batches = batch + 1\n",
    "    total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "    ##\n",
    "    # Print average loss-so-far for epoch\n",
    "    # If using train_loss_, this may be an underestimate.\n",
    "    if verbose and (time.time() - tick_time >= tick_s):\n",
    "        avg_cost = total_cost / total_batches\n",
    "        avg_wps = total_words / (time.time() - start_time)\n",
    "        print(\"[batch {:d}]: seen {:d} words at {:.1f} wps, loss = {:.3f}\".format(\n",
    "            batch, total_words, avg_wps, avg_cost))\n",
    "        tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = utils.rnnlm_batch_generator(ids, batch_size=100, max_time=100)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=0.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print(\"{:s}: avg. loss: {:.03f}  (perplexity: {:.02f})\".format(name, cost, np.exp(cost)))\n",
    "    return cost\n",
    "\n",
    "\n",
    "#build a list of list of characters from the 5-star reviews\n",
    "def preprocess_review_series(review_series):\n",
    "    review_list = []\n",
    "    for new_review in review_series:\n",
    "        clipped_review = new_review[2:-1]\n",
    "        char_list = list(clipped_review.lower())\n",
    "        semifinal_review = []\n",
    "        last_char = ''\n",
    "        for ascii_char in char_list:\n",
    "            if ascii_char == '\\\\' or last_char == '\\\\':\n",
    "                pass\n",
    "            else:\n",
    "                semifinal_review.append(ascii_char)\n",
    "            last_char = ascii_char\n",
    "        if len(semifinal_review) > 300:\n",
    "            final_review = ['<SOR>'] + semifinal_review + ['<EOR>']\n",
    "            #print(final_review)\n",
    "            review_list.append(final_review)\n",
    "    return review_list\n",
    "\n",
    "def get_review_series(review_path = '/home/kalvin_kao/yelp_challenge_dataset/review.csv'):\n",
    "    #review_path = '/home/kalvin_kao/yelp_challenge_dataset/review.csv'\n",
    "    review_df = pd.read_csv(review_path)\n",
    "    five_star_review_df = review_df[review_df['stars']==5]\n",
    "    #five_star_review_series = five_star_review_df['text']\n",
    "    return five_star_review_df['text']\n",
    "\n",
    "def get_business_list(business_path = '/home/kalvin_kao/yelp_challenge_dataset/business.csv'):\n",
    "    #business_path = '/home/kalvin_kao/yelp_challenge_dataset/business.csv'\n",
    "    return pd.read_csv(business_path)\n",
    "\n",
    "def split_train_test(review_list, training_samples, test_samples):\n",
    "    #pass in randomized review list\n",
    "    train_len = int(np.floor(0.8*len(review_list)))\n",
    "    test_len = int(np.floor(0.2*len(review_list)))\n",
    "    training_review_list = review_list[:train_len]\n",
    "    testing_review_list = review_list[-test_len:]\n",
    "    randomized_training_list = random.sample(training_review_list, training_samples)\n",
    "    randomized_testing_list = random.sample(testing_review_list, test_samples)\n",
    "    training_review_list = [item for sublist in randomized_training_list for item in sublist]\n",
    "    print(\"number of training characters\", len(training_review_list))\n",
    "    test_review_list = [item for sublist in randomized_testing_list for item in sublist]\n",
    "    print(\"number of test characters\", len(test_review_list))\n",
    "    return randomized_training_list, randomized_testing_list\n",
    "\n",
    "def make_train_test_data(five_star_review_series, training_samples=20000, test_samples=1000):\n",
    "    #fix randomization to prevent evaluation on trained samples\n",
    "    review_list = preprocess_review_series(five_star_review_series)\n",
    "    #split and shuffle the data\n",
    "    train_len = int(np.floor(0.8*len(review_list)))\n",
    "    test_len = int(np.floor(0.2*len(review_list)))\n",
    "    np.random.shuffle(review_list)\n",
    "    training_review_list = review_list[:train_len]\n",
    "    testing_review_list = review_list[-test_len:]\n",
    "    randomized_training_list = random.sample(training_review_list, training_samples)\n",
    "    randomized_testing_list = random.sample(testing_review_list, test_samples)\n",
    "    #training_review_list = [item for sublist in review_list[:training_samples] for item in sublist]\n",
    "    training_review_list = [item for sublist in randomized_training_list for item in sublist]\n",
    "    print(\"number of training characters\", len(training_review_list))\n",
    "    \n",
    "    #test_review_list = [item for sublist in review_list[training_samples:training_samples+test_samples] for item in sublist]\n",
    "    test_review_list = [item for sublist in randomized_testing_list for item in sublist]\n",
    "    print(\"number of test characters\", len(test_review_list))\n",
    "    return training_review_list, test_review_list\n",
    "\n",
    "\n",
    "#def make_vocabulary(training_review_list, test_review_list):\n",
    "#    unique_characters = list(set(training_review_list + test_review_list))\n",
    "#    #vocabulary\n",
    "#    char_dict = {w:i for i, w in enumerate(unique_characters)}\n",
    "#    ids_to_words = {v: k for k, v in char_dict.items()}\n",
    "#    return char_dict, ids_to_words\n",
    "def make_vocabulary(dataset_list):\n",
    "    unique_characters = list(set().union(*dataset_list))\n",
    "    #unique_characters = list(set(training_review_list + test_review_list))\n",
    "    #vocabulary\n",
    "    char_dict = {w:i for i, w in enumerate(unique_characters)}\n",
    "    ids_to_words = {v: k for k, v in char_dict.items()}\n",
    "    return char_dict, ids_to_words\n",
    "\n",
    "def convert_to_ids(char_dict, review_list):\n",
    "    #convert to flat (1D) np.array(int) of ids\n",
    "    review_ids = [char_dict.get(token) for token in review_list]\n",
    "    return np.array(review_ids)\n",
    "\n",
    "def run_training(train_list, test_ids, words_to_ids, ids_to_words, tf_savedir, model_params, max_time=100, batch_size=256, learning_rate=0.002, num_epochs=20):\n",
    "    #V = len(words_to_ids.keys())\n",
    "    # Training parameters\n",
    "    ## add parameter sets for each attack/defense configuration\n",
    "    #max_time = 25\n",
    "    #batch_size = 100\n",
    "    #learning_rate = 0.01\n",
    "    #num_epochs = 10\n",
    "    \n",
    "    # Model parameters\n",
    "    #model_params = dict(V=vocab.size, \n",
    "                        #H=200, \n",
    "                        #softmax_ns=200,\n",
    "                        #num_layers=2)\n",
    "    #model_params = dict(V=len(words_to_ids.keys()), \n",
    "                        #H=1024, \n",
    "                        #softmax_ns=len(words_to_ids.keys()),\n",
    "                        #num_layers=2)\n",
    "    #model_params = dict(V=V, H=H, softmax_ns=softmax_ns, num_layers=num_layers)\n",
    "    \n",
    "    #TF_SAVEDIR = \"/tmp/artificial_hotel_reviews/a4_model\"\n",
    "    TF_SAVEDIR = tf_savedir\n",
    "    checkpoint_filename = os.path.join(TF_SAVEDIR, \"gan\")\n",
    "    trained_filename = os.path.join(TF_SAVEDIR, \"gan_trained\")\n",
    "    \n",
    "    # Will print status every this many seconds\n",
    "    #print_interval = 5\n",
    "    print_interval = 30\n",
    "    \n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    lm.BuildTrainGraph()\n",
    "    ### UPDATED!!!\n",
    "    lm.BuildSamplerGraph()\n",
    "    num_pretrain = 15000\n",
    "    #num_pretrain = 200#low number for testing\n",
    "    #pretrain on a different set of training data each time\n",
    "    #train and test ids \n",
    "    #pre_train_ids =\n",
    "    #train_ids = \n",
    "    ### UPDATED!!!\n",
    "    \n",
    "    # Explicitly add global initializer and variable saver to LM graph\n",
    "    with lm.graph.as_default():\n",
    "        initializer = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    # Clear old log directory\n",
    "    shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "    if not os.path.isdir(TF_SAVEDIR):\n",
    "        os.makedirs(TF_SAVEDIR)\n",
    "    \n",
    "    with tf.Session(graph=lm.graph) as session:\n",
    "        # Seed RNG for repeatability\n",
    "        #tf.set_random_seed(42)\n",
    "    \n",
    "        session.run(initializer)\n",
    "        \n",
    "        #check trainable variables\n",
    "        #variables_names = [v.name for v in tf.trainable_variables()]\n",
    "        #values = session.run(variables_names)\n",
    "        #for k, v in zip(variables_names, values):\n",
    "            #print(\"Variable: \", k)\n",
    "            #print(\"Shape: \", v.shape)\n",
    "            #print(v)\n",
    "    \n",
    "        for epoch in range(1,num_epochs+1):\n",
    "            t0_epoch = time.time()\n",
    "            np.random.shuffle(train_list)\n",
    "            #shuffled_train_list = np.random.shuffle(train_list)\n",
    "            #pre_train_ids = [item for sublist in shuffled_train_list[:num_pretrain] for item in sublist]\n",
    "            #gan_train_list = shuffled_train_list[num_pretrain:]\n",
    "            #train_list = \n",
    "            pre_train_ids = np.array([item for sublist in train_list[:num_pretrain] for item in sublist])\n",
    "            #print(pre_train_ids.shape)\n",
    "            #pre_train_ids = np.array(pre_train_ids)\n",
    "            gan_train_list = train_list[num_pretrain:]\n",
    "            if num_pretrain > 0:\n",
    "                bi = utils.rnnlm_batch_generator(pre_train_ids, batch_size, max_time)\n",
    "                print(\"[epoch {:d}] Starting epoch {:d}\".format(epoch, epoch))\n",
    "                # Run a pretraining epoch.\n",
    "                run_epoch(lm, session, batch_iterator=bi, train=True, verbose=True, tick_s=10, learning_rate=learning_rate)\n",
    "\n",
    "                print(\"[epoch {:d}] Completed in {:s}\".format(epoch, utils.pretty_timedelta(since=t0_epoch)))\n",
    "        \n",
    "            #now train gan\n",
    "            #run_gan_epoch(lm, session, words_to_ids, ids_to_words, train_list, verbose=False, tick_s=10, learning_rate=None)\n",
    "            run_gan_epoch(lm, session, words_to_ids, ids_to_words, gan_train_list, batch_size, \n",
    "                          verbose=True, tick_s=10, learning_rate=learning_rate)\n",
    "        \n",
    "            # Save a checkpoint\n",
    "            saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "        \n",
    "            ##\n",
    "            # score_dataset will run a forward pass over the entire dataset\n",
    "            # and report perplexity scores. This can be slow (around 1/2 to \n",
    "            # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "            # to speed up training on a slow machine. Be sure to run it at the \n",
    "            # end to evaluate your score.\n",
    "            print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "            score_dataset(lm, session, pre_train_ids, name=\"Train set\")\n",
    "            print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "            score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "            print(\"\")\n",
    "        \n",
    "        # Save final model\n",
    "        saver.save(session, trained_filename)\n",
    "        return trained_filename\n",
    "\n",
    "def get_char_probs(trained_filename, model_params, test_ids):\n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    all_review_likelihoods = []\n",
    "    train_op = tf.no_op()\n",
    "    use_dropout = False\n",
    "    loss = lm.loss_\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session(graph=lm.graph) as session:\n",
    "        #train_op = tf.no_op()\n",
    "        #use_dropout = False\n",
    "        #loss = lm.loss_\n",
    "        \n",
    "        saver.restore(session, trained_filename)\n",
    "        \n",
    "        for review in test_ids:\n",
    "            review_likelihoods = []\n",
    "            inputs = review[:-1]\n",
    "            labels = review[1:]\n",
    "            inputs_labels = zip(inputs,labels)\n",
    "            for i, (w,y) in enumerate(inputs_labels):\n",
    "                \n",
    "                w = np.array(w)\n",
    "                y = np.array(y)\n",
    "                w = w.reshape([1,1])\n",
    "                y = y.reshape([1,1])\n",
    "                \n",
    "                if i == 0:\n",
    "                    h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "                feed_dict = {lm.input_w_:w, \n",
    "                             lm.target_y_:y,\n",
    "                             lm.learning_rate_: 0.002,\n",
    "                             lm.use_dropout_: use_dropout,\n",
    "                             lm.initial_h_:h}\n",
    "                cost, h = session.run([loss, lm.final_h_],feed_dict=feed_dict)\n",
    "                likelihood = 2**(-1*cost)\n",
    "                review_likelihoods.append(likelihood)\n",
    "            all_review_likelihoods.append(review_likelihoods)\n",
    "    return all_review_likelihoods\n",
    "\n",
    "## Sampling\n",
    "def sample_step(lm, session, input_w, initial_h):\n",
    "    \"\"\"Run a single RNN step and return sampled predictions.\n",
    "  \n",
    "    Args:\n",
    "      lm : rnnlm.RNNLM\n",
    "      session: tf.Session\n",
    "      input_w : [batch_size] vector of indices\n",
    "      initial_h : [batch_size, hidden_dims] initial state\n",
    "    \n",
    "    Returns:\n",
    "      final_h : final hidden state, compatible with initial_h\n",
    "      samples : [batch_size, 1] vector of indices\n",
    "    \"\"\"\n",
    "    # Reshape input to column vector\n",
    "    input_w = np.array(input_w, dtype=np.int32).reshape([-1,1])\n",
    "\n",
    "    # Run sample ops\n",
    "    feed_dict = {lm.input_w_:input_w, lm.initial_h_:initial_h}\n",
    "    final_h, samples = session.run([lm.final_h_, lm.pred_samples_], feed_dict=feed_dict)\n",
    "\n",
    "    # Note indexing here: \n",
    "    #   [batch_size, max_time, 1] -> [batch_size, 1]\n",
    "    return final_h, samples[:,-1,:]\n",
    "\n",
    "def generate_text(trained_filename, model_params, words_to_ids, ids_to_words):\n",
    "    # Same as above, but as a batch\n",
    "    #max_steps = 20\n",
    "    max_steps = 300\n",
    "    #num_samples = 40000\n",
    "    num_samples = 40\n",
    "    random_seed = 42\n",
    "    \n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    lm.BuildSamplerGraph()\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session(graph=lm.graph) as session:\n",
    "        # Seed RNG for repeatability\n",
    "        #tf.set_random_seed(random_seed)\n",
    "        \n",
    "        # Load the trained model\n",
    "        saver.restore(session, trained_filename)\n",
    "    \n",
    "        # Make initial state for a batch with batch_size = num_samples\n",
    "        #w = np.repeat([[vocab.START_ID]], num_samples, axis=0)\n",
    "        w = np.repeat([[words_to_ids.get('<SOR>')]], num_samples, axis=0)\n",
    "        h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "        # take one step for each sequence on each iteration \n",
    "        for i in range(max_steps):\n",
    "            h, y = sample_step(lm, session, w[:,-1:], h)\n",
    "            w = np.hstack((w,y))\n",
    "    \n",
    "        # Print generated sentences\n",
    "        for row in w:\n",
    "            print(trained_filename, end=\":  \")\n",
    "            for i, word_id in enumerate(row):\n",
    "                #print(vocab.id_to_word[word_id], end=\" \")\n",
    "                print(ids_to_words[word_id], end=\"\")\n",
    "                #if (i != 0) and (word_id == vocab.START_ID):\n",
    "                if (i != 0) and (word_id == words_to_ids.get(\"<EOR>\")):\n",
    "                    break\n",
    "            print(\"\")\n",
    "\n",
    "def train_attack_model(training_samples=20000, test_samples=1000, review_path = '/home/kalvin_kao/yelp_challenge_dataset/review.csv'):\n",
    "    #training_samples=20000\n",
    "    #test_samples=1000\n",
    "    #review_path = '/home/kalvin_kao/yelp_challenge_dataset/review.csv'\n",
    "    start_format = time.time()\n",
    "    five_star_reviews = get_review_series(review_path)\n",
    "    train_review_list, test_review_list = make_train_test_data(five_star_reviews, training_samples, test_samples)\n",
    "    words_to_ids, ids_to_words = make_vocabulary(train_review_list, test_review_list)\n",
    "    train_ids = convert_to_ids(words_to_ids, train_review_list)\n",
    "    test_ids = convert_to_ids(words_to_ids, test_review_list)\n",
    "    end_format = time.time()\n",
    "    print(\"data formatting took \" + str(end_format-start_format) + \" seconds\")\n",
    "    model_params = dict(V=len(words_to_ids.keys()), \n",
    "                            H=1024, \n",
    "                            softmax_ns=len(words_to_ids.keys()),\n",
    "                            num_layers=2)\n",
    "    #run_training(train_ids, test_ids, tf_savedir, model_params, max_time=100, batch_size=256, learning_rate=0.002, num_epochs=20)\n",
    "    trained_filename = run_training(train_ids, test_ids, tf_savedir = \"/tmp/artificial_hotel_reviews/a4_model\", model_params=model_params, max_time=150, batch_size=256, learning_rate=0.002, num_epochs=20)\n",
    "    return trained_filename, model_params, words_to_ids, ids_to_words\n",
    "\n",
    "def neg_log_lik_ratio(likelihoods_real, likelihoods_artificial):\n",
    "    predictions = []\n",
    "    combined = zip(likelihoods_real, likelihoods_artificial)\n",
    "    for (real_review_likelihoods, artificial_review_likelihoods) in combined:\n",
    "        negative_log_lik_ratios = -1*(np.log(np.divide(real_review_likelihoods, artificial_review_likelihoods)))\n",
    "        #averaged_llrs = negative_log_lik_ratios[:-1]/(len(negative_log_lik_ratios)-1)\n",
    "        averaged_llrs = np.sum(negative_log_lik_ratios[:-1])/(len(negative_log_lik_ratios)-1)\n",
    "        predictions.append(averaged_llrs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data download took 4.29355525970459 seconds\n"
     ]
    }
   ],
   "source": [
    "start_dl = time.time()\n",
    "os.system('gsutil -q cp gs://w266_final_project_kk/data/split01_train_data_03.csv .')\n",
    "os.system('gsutil -q cp gs://w266_final_project_kk/data/split01_test_data_03.csv .')\n",
    "#os.system('gsutil -q cp gs://w266_final_project_kk/data/gen01_train_data_01.csv .')\n",
    "#os.system('gsutil -q cp gs://w266_final_project_kk/data/gen01_test_data_01.csv .')\n",
    "end_dl = time.time()\n",
    "print(\"data download took \" + str(end_dl-start_dl) + \" seconds\")\n",
    "#gsutil cp gs://[BUCKET_NAME]/[OBJECT_NAME] [OBJECT_DESTINATION]\n",
    "real_train_review_path = './split01_train_data_02.csv'\n",
    "real_test_review_path = './split01_test_data_02.csv'\n",
    "#artificial_train_review_path = './gen01_train_data_01.csv'\n",
    "#artificial_test_review_path = './gen01_test_data_01.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_train_review_path = '/home/kalvin_kao/final_project/split01_train_data_02.csv'\n",
    "real_test_review_path = '/home/kalvin_kao/final_project/split01_test_data_02.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data reading took 1.669154167175293 seconds\n"
     ]
    }
   ],
   "source": [
    "start_open = time.time()\n",
    "with open(real_train_review_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    training_review_list_real = [sublist for sublist in reader]\n",
    "training_review_list_real_training_eval = [item for sublist in training_review_list_real for item in sublist]\n",
    "\n",
    "with open(real_test_review_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    test_review_list_real = [sublist for sublist in reader]\n",
    "    #make into list of list\n",
    "test_review_list_real_training_eval = [item for sublist in test_review_list_real for item in sublist]\n",
    "\n",
    "#with open(artificial_train_review_path, 'r') as csvfile:\n",
    "    #reader = csv.reader(csvfile, delimiter=',')\n",
    "    #training_review_list_artificial = [item for sublist in reader for item in sublist]\n",
    "\n",
    "#with open(artificial_test_review_path, 'r') as csvfile:\n",
    "    #reader = csv.reader(csvfile, delimiter=',')\n",
    "    #test_review_list_artificial = [sublist for sublist in reader]\n",
    "    #make into list of list\n",
    "#test_review_list_artificial_training_eval = [item for sublist in test_review_list_artificial for item in sublist]\n",
    "end_open = time.time()\n",
    "print(\"data reading took \" + str(end_open-start_open) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary building took 7.532317638397217 seconds\n"
     ]
    }
   ],
   "source": [
    "start_vocab = time.time()\n",
    "#words_to_ids, ids_to_words = make_vocabulary([training_review_list_real, test_review_list_real_training_eval, training_review_list_artificial, test_review_list_artificial_training_eval])\n",
    "words_to_ids, ids_to_words = make_vocabulary([training_review_list_real_training_eval, test_review_list_real_training_eval])\n",
    "train_ids_real = [convert_to_ids(words_to_ids, review) for review in training_review_list_real]\n",
    "train_ids_real_training_eval = convert_to_ids(words_to_ids, training_review_list_real_training_eval)\n",
    "test_ids_real = [convert_to_ids(words_to_ids, review) for review in test_review_list_real]\n",
    "test_ids_real_training_eval = convert_to_ids(words_to_ids, test_review_list_real_training_eval)\n",
    "#train_ids_artificial = convert_to_ids(words_to_ids, training_review_list_artificial)\n",
    "#test_ids_artificial = [convert_to_ids(words_to_ids, review) for review in test_review_list_artificial]\n",
    "#test_ids_artificial_training_eval = convert_to_ids(words_to_ids, test_review_list_artificial_training_eval)\n",
    "end_vocab = time.time()\n",
    "print(\"vocabulary building took \" + str(end_vocab-start_vocab) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.random.shuffle(train_ids_real[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trainer.rnnlm' from '/home/kalvin_kao/artificial_hotel_reviews/model_dev/gan/trainer/rnnlm.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnnlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kalvin_kao/artificial_hotel_reviews/model_dev/gan/trainer/rnnlm.py:352: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "[epoch 1] Starting epoch 1\n",
      "[batch 2]: seen 28800 words at 1905.5 wps, loss = 25.574\n",
      "[batch 5]: seen 57600 words at 1956.8 wps, loss = 21.403\n",
      "[batch 8]: seen 86400 words at 1989.7 wps, loss = 16.691\n",
      "[batch 11]: seen 115200 words at 2022.8 wps, loss = 13.369\n",
      "[batch 14]: seen 144000 words at 2023.3 wps, loss = 11.258\n",
      "[batch 17]: seen 172800 words at 2033.7 wps, loss = 9.826\n",
      "[batch 20]: seen 201600 words at 2038.2 wps, loss = 8.791\n",
      "[batch 23]: seen 230400 words at 2042.3 wps, loss = 8.007\n",
      "[batch 26]: seen 259200 words at 2050.0 wps, loss = 7.394\n",
      "[batch 29]: seen 288000 words at 2048.3 wps, loss = 6.898\n",
      "[batch 32]: seen 316800 words at 2053.9 wps, loss = 6.487\n",
      "[batch 35]: seen 345600 words at 2057.0 wps, loss = 6.142\n",
      "[batch 38]: seen 374400 words at 2059.4 wps, loss = 5.850\n",
      "[batch 41]: seen 403200 words at 2061.4 wps, loss = 5.597\n",
      "[batch 44]: seen 432000 words at 2066.2 wps, loss = 5.376\n",
      "[batch 47]: seen 460800 words at 2061.7 wps, loss = 5.181\n",
      "[batch 50]: seen 489600 words at 2065.1 wps, loss = 5.008\n",
      "[batch 53]: seen 518400 words at 2065.2 wps, loss = 4.853\n",
      "[batch 56]: seen 547200 words at 2066.0 wps, loss = 4.714\n",
      "[batch 59]: seen 576000 words at 2069.7 wps, loss = 4.586\n",
      "[batch 62]: seen 604800 words at 2068.4 wps, loss = 4.470\n",
      "[batch 65]: seen 633600 words at 2068.8 wps, loss = 4.362\n",
      "[batch 68]: seen 662400 words at 2070.1 wps, loss = 4.264\n",
      "[batch 71]: seen 691200 words at 2071.7 wps, loss = 4.174\n",
      "[batch 74]: seen 720000 words at 2072.4 wps, loss = 4.091\n",
      "[batch 77]: seen 748800 words at 2075.5 wps, loss = 4.014\n",
      "[batch 80]: seen 777600 words at 2073.5 wps, loss = 3.941\n",
      "[batch 83]: seen 806400 words at 2074.3 wps, loss = 3.873\n",
      "[batch 86]: seen 835200 words at 2074.8 wps, loss = 3.809\n",
      "[batch 89]: seen 864000 words at 2076.2 wps, loss = 3.750\n",
      "[batch 92]: seen 892800 words at 2076.5 wps, loss = 3.693\n",
      "[batch 95]: seen 921600 words at 2078.0 wps, loss = 3.640\n",
      "[batch 98]: seen 950400 words at 2075.4 wps, loss = 3.590\n",
      "[batch 101]: seen 979200 words at 2075.7 wps, loss = 3.543\n",
      "[batch 104]: seen 1008000 words at 2075.1 wps, loss = 3.499\n",
      "[batch 107]: seen 1036800 words at 2076.3 wps, loss = 3.456\n",
      "[batch 110]: seen 1065600 words at 2077.5 wps, loss = 3.415\n",
      "[batch 113]: seen 1094400 words at 2078.8 wps, loss = 3.378\n",
      "[batch 116]: seen 1123200 words at 2078.0 wps, loss = 3.342\n",
      "[batch 119]: seen 1152000 words at 2080.4 wps, loss = 3.308\n",
      "[batch 122]: seen 1180800 words at 2083.6 wps, loss = 3.276\n",
      "[batch 125]: seen 1209600 words at 2087.0 wps, loss = 3.245\n",
      "[batch 128]: seen 1238400 words at 2089.9 wps, loss = 3.214\n",
      "[batch 131]: seen 1267200 words at 2093.7 wps, loss = 3.185\n",
      "[batch 134]: seen 1296000 words at 2098.7 wps, loss = 3.157\n",
      "[batch 137]: seen 1324800 words at 2103.4 wps, loss = 3.130\n",
      "[batch 140]: seen 1353600 words at 2108.9 wps, loss = 3.104\n",
      "[batch 143]: seen 1382400 words at 2113.2 wps, loss = 3.079\n",
      "[batch 146]: seen 1411200 words at 2118.6 wps, loss = 3.055\n",
      "[batch 149]: seen 1440000 words at 2123.5 wps, loss = 3.032\n",
      "[batch 152]: seen 1468800 words at 2126.7 wps, loss = 3.009\n",
      "[batch 155]: seen 1497600 words at 2129.0 wps, loss = 2.987\n",
      "[batch 158]: seen 1526400 words at 2128.6 wps, loss = 2.966\n",
      "[batch 161]: seen 1555200 words at 2127.2 wps, loss = 2.946\n",
      "[batch 164]: seen 1584000 words at 2127.7 wps, loss = 2.927\n",
      "[batch 167]: seen 1612800 words at 2127.3 wps, loss = 2.907\n",
      "[batch 170]: seen 1641600 words at 2127.5 wps, loss = 2.890\n",
      "[batch 173]: seen 1670400 words at 2125.2 wps, loss = 2.873\n",
      "[batch 176]: seen 1699200 words at 2124.8 wps, loss = 2.856\n",
      "[batch 179]: seen 1728000 words at 2123.6 wps, loss = 2.840\n",
      "[batch 182]: seen 1756800 words at 2123.3 wps, loss = 2.823\n",
      "[batch 185]: seen 1785600 words at 2123.5 wps, loss = 2.808\n",
      "[batch 188]: seen 1814400 words at 2122.9 wps, loss = 2.793\n",
      "[batch 191]: seen 1843200 words at 2121.7 wps, loss = 2.778\n",
      "[batch 194]: seen 1872000 words at 2121.7 wps, loss = 2.764\n",
      "[batch 197]: seen 1900800 words at 2120.8 wps, loss = 2.750\n",
      "[batch 200]: seen 1929600 words at 2120.3 wps, loss = 2.736\n",
      "[batch 203]: seen 1958400 words at 2120.9 wps, loss = 2.722\n",
      "[batch 206]: seen 1987200 words at 2119.1 wps, loss = 2.708\n",
      "[batch 209]: seen 2016000 words at 2118.8 wps, loss = 2.696\n",
      "[batch 212]: seen 2044800 words at 2118.4 wps, loss = 2.684\n",
      "[batch 215]: seen 2073600 words at 2118.1 wps, loss = 2.671\n",
      "[batch 218]: seen 2102400 words at 2117.9 wps, loss = 2.660\n",
      "[batch 221]: seen 2131200 words at 2118.3 wps, loss = 2.648\n",
      "[batch 224]: seen 2160000 words at 2116.4 wps, loss = 2.637\n",
      "[batch 227]: seen 2188800 words at 2116.2 wps, loss = 2.626\n",
      "[batch 230]: seen 2217600 words at 2115.6 wps, loss = 2.615\n",
      "[batch 233]: seen 2246400 words at 2115.3 wps, loss = 2.605\n",
      "[batch 236]: seen 2275200 words at 2115.5 wps, loss = 2.595\n",
      "[batch 239]: seen 2304000 words at 2115.2 wps, loss = 2.585\n",
      "[batch 242]: seen 2332800 words at 2114.4 wps, loss = 2.576\n",
      "[batch 245]: seen 2361600 words at 2114.1 wps, loss = 2.566\n",
      "[batch 248]: seen 2390400 words at 2113.8 wps, loss = 2.556\n",
      "[batch 251]: seen 2419200 words at 2113.2 wps, loss = 2.546\n",
      "[batch 254]: seen 2448000 words at 2113.2 wps, loss = 2.537\n",
      "[batch 257]: seen 2476800 words at 2112.3 wps, loss = 2.528\n",
      "[batch 260]: seen 2505600 words at 2112.0 wps, loss = 2.519\n",
      "[batch 263]: seen 2534400 words at 2111.5 wps, loss = 2.510\n",
      "[batch 266]: seen 2563200 words at 2111.7 wps, loss = 2.502\n",
      "[batch 269]: seen 2592000 words at 2111.7 wps, loss = 2.493\n",
      "[batch 272]: seen 2620800 words at 2111.9 wps, loss = 2.484\n",
      "[batch 275]: seen 2649600 words at 2110.8 wps, loss = 2.476\n",
      "[batch 278]: seen 2678400 words at 2110.6 wps, loss = 2.468\n",
      "[batch 281]: seen 2707200 words at 2109.8 wps, loss = 2.460\n",
      "[batch 284]: seen 2736000 words at 2109.6 wps, loss = 2.452\n",
      "[batch 287]: seen 2764800 words at 2110.0 wps, loss = 2.444\n",
      "[batch 290]: seen 2793600 words at 2109.3 wps, loss = 2.437\n",
      "[batch 293]: seen 2822400 words at 2108.9 wps, loss = 2.429\n",
      "[batch 296]: seen 2851200 words at 2109.0 wps, loss = 2.422\n",
      "[batch 299]: seen 2880000 words at 2108.4 wps, loss = 2.415\n",
      "[batch 302]: seen 2908800 words at 2108.2 wps, loss = 2.408\n",
      "[batch 305]: seen 2937600 words at 2108.5 wps, loss = 2.402\n",
      "[batch 308]: seen 2966400 words at 2107.6 wps, loss = 2.395\n",
      "[batch 311]: seen 2995200 words at 2107.5 wps, loss = 2.389\n",
      "[batch 314]: seen 3024000 words at 2107.4 wps, loss = 2.382\n",
      "[batch 317]: seen 3052800 words at 2107.3 wps, loss = 2.376\n",
      "[batch 320]: seen 3081600 words at 2107.2 wps, loss = 2.370\n",
      "[batch 323]: seen 3110400 words at 2107.7 wps, loss = 2.363\n",
      "[batch 326]: seen 3139200 words at 2106.6 wps, loss = 2.357\n",
      "[batch 329]: seen 3168000 words at 2106.5 wps, loss = 2.352\n",
      "[batch 332]: seen 3196800 words at 2107.6 wps, loss = 2.346\n",
      "[batch 335]: seen 3225600 words at 2108.6 wps, loss = 2.340\n",
      "[batch 338]: seen 3254400 words at 2109.8 wps, loss = 2.334\n",
      "[batch 341]: seen 3283200 words at 2111.1 wps, loss = 2.328\n",
      "[batch 344]: seen 3312000 words at 2112.0 wps, loss = 2.323\n",
      "[batch 347]: seen 3340800 words at 2113.0 wps, loss = 2.317\n",
      "[batch 350]: seen 3369600 words at 2112.5 wps, loss = 2.312\n",
      "[batch 353]: seen 3398400 words at 2112.5 wps, loss = 2.307\n",
      "[batch 356]: seen 3427200 words at 2112.0 wps, loss = 2.302\n",
      "[batch 359]: seen 3456000 words at 2111.9 wps, loss = 2.297\n",
      "[batch 362]: seen 3484800 words at 2111.9 wps, loss = 2.293\n",
      "[batch 365]: seen 3513600 words at 2111.2 wps, loss = 2.288\n",
      "[batch 368]: seen 3542400 words at 2111.1 wps, loss = 2.283\n",
      "[batch 371]: seen 3571200 words at 2110.9 wps, loss = 2.278\n",
      "[batch 374]: seen 3600000 words at 2111.0 wps, loss = 2.274\n",
      "[batch 377]: seen 3628800 words at 2110.9 wps, loss = 2.269\n",
      "[batch 380]: seen 3657600 words at 2111.1 wps, loss = 2.264\n",
      "[batch 383]: seen 3686400 words at 2110.2 wps, loss = 2.259\n",
      "[batch 386]: seen 3715200 words at 2110.1 wps, loss = 2.255\n",
      "[batch 389]: seen 3744000 words at 2109.6 wps, loss = 2.250\n",
      "[batch 392]: seen 3772800 words at 2109.7 wps, loss = 2.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 395]: seen 3801600 words at 2109.9 wps, loss = 2.242\n",
      "[batch 398]: seen 3830400 words at 2109.7 wps, loss = 2.237\n",
      "[batch 401]: seen 3859200 words at 2109.1 wps, loss = 2.233\n",
      "[batch 404]: seen 3888000 words at 2108.9 wps, loss = 2.229\n",
      "[batch 407]: seen 3916800 words at 2108.6 wps, loss = 2.224\n",
      "[batch 410]: seen 3945600 words at 2108.4 wps, loss = 2.220\n",
      "[batch 413]: seen 3974400 words at 2108.7 wps, loss = 2.216\n",
      "[batch 416]: seen 4003200 words at 2107.9 wps, loss = 2.212\n",
      "[batch 419]: seen 4032000 words at 2107.7 wps, loss = 2.208\n",
      "[batch 422]: seen 4060800 words at 2107.5 wps, loss = 2.205\n",
      "[batch 425]: seen 4089600 words at 2107.5 wps, loss = 2.201\n",
      "[batch 428]: seen 4118400 words at 2107.5 wps, loss = 2.197\n",
      "[batch 431]: seen 4147200 words at 2107.8 wps, loss = 2.194\n",
      "[batch 434]: seen 4176000 words at 2107.1 wps, loss = 2.190\n",
      "[batch 437]: seen 4204800 words at 2107.0 wps, loss = 2.186\n",
      "[batch 440]: seen 4233600 words at 2106.6 wps, loss = 2.183\n",
      "[batch 443]: seen 4262400 words at 2106.4 wps, loss = 2.179\n",
      "[batch 446]: seen 4291200 words at 2106.5 wps, loss = 2.175\n",
      "[batch 449]: seen 4320000 words at 2106.3 wps, loss = 2.172\n",
      "[batch 452]: seen 4348800 words at 2106.0 wps, loss = 2.169\n",
      "[batch 455]: seen 4377600 words at 2105.6 wps, loss = 2.165\n",
      "[batch 458]: seen 4406400 words at 2105.5 wps, loss = 2.162\n",
      "[batch 461]: seen 4435200 words at 2105.6 wps, loss = 2.159\n",
      "[batch 464]: seen 4464000 words at 2105.9 wps, loss = 2.155\n",
      "[batch 467]: seen 4492800 words at 2105.3 wps, loss = 2.152\n",
      "[batch 470]: seen 4521600 words at 2105.4 wps, loss = 2.149\n",
      "[batch 473]: seen 4550400 words at 2105.1 wps, loss = 2.146\n",
      "[batch 476]: seen 4579200 words at 2105.1 wps, loss = 2.142\n",
      "[batch 479]: seen 4608000 words at 2105.4 wps, loss = 2.139\n",
      "[batch 482]: seen 4636800 words at 2105.5 wps, loss = 2.136\n",
      "[batch 485]: seen 4665600 words at 2105.0 wps, loss = 2.132\n",
      "[batch 488]: seen 4694400 words at 2105.0 wps, loss = 2.129\n",
      "[batch 491]: seen 4723200 words at 2104.6 wps, loss = 2.126\n",
      "[batch 494]: seen 4752000 words at 2104.6 wps, loss = 2.123\n",
      "[batch 497]: seen 4780800 words at 2104.8 wps, loss = 2.119\n",
      "[batch 500]: seen 4809600 words at 2105.0 wps, loss = 2.116\n",
      "[batch 503]: seen 4838400 words at 2104.4 wps, loss = 2.113\n",
      "[batch 506]: seen 4867200 words at 2104.4 wps, loss = 2.110\n",
      "[batch 509]: seen 4896000 words at 2104.2 wps, loss = 2.106\n",
      "[batch 512]: seen 4924800 words at 2104.2 wps, loss = 2.103\n",
      "[batch 515]: seen 4953600 words at 2104.2 wps, loss = 2.100\n",
      "[batch 518]: seen 4982400 words at 2104.2 wps, loss = 2.097\n",
      "[batch 521]: seen 5011200 words at 2104.4 wps, loss = 2.094\n",
      "[batch 524]: seen 5040000 words at 2104.4 wps, loss = 2.092\n",
      "[batch 527]: seen 5068800 words at 2104.3 wps, loss = 2.089\n",
      "[batch 530]: seen 5097600 words at 2104.7 wps, loss = 2.086\n",
      "[batch 533]: seen 5126400 words at 2104.5 wps, loss = 2.083\n",
      "[batch 536]: seen 5155200 words at 2104.6 wps, loss = 2.081\n",
      "[batch 539]: seen 5184000 words at 2104.9 wps, loss = 2.078\n",
      "[batch 542]: seen 5212800 words at 2105.2 wps, loss = 2.075\n",
      "[batch 545]: seen 5241600 words at 2105.4 wps, loss = 2.073\n",
      "[batch 548]: seen 5270400 words at 2105.8 wps, loss = 2.070\n",
      "[batch 551]: seen 5299200 words at 2105.7 wps, loss = 2.067\n",
      "[batch 554]: seen 5328000 words at 2105.9 wps, loss = 2.064\n",
      "[batch 557]: seen 5356800 words at 2106.3 wps, loss = 2.062\n",
      "[batch 560]: seen 5385600 words at 2106.7 wps, loss = 2.059\n",
      "[batch 563]: seen 5414400 words at 2106.5 wps, loss = 2.056\n",
      "[batch 566]: seen 5443200 words at 2106.3 wps, loss = 2.053\n",
      "[batch 569]: seen 5472000 words at 2106.5 wps, loss = 2.051\n",
      "[batch 572]: seen 5500800 words at 2106.6 wps, loss = 2.048\n",
      "[batch 575]: seen 5529600 words at 2106.6 wps, loss = 2.045\n",
      "[batch 578]: seen 5558400 words at 2106.2 wps, loss = 2.043\n",
      "[batch 581]: seen 5587200 words at 2106.1 wps, loss = 2.040\n",
      "[batch 584]: seen 5616000 words at 2106.0 wps, loss = 2.038\n",
      "[batch 587]: seen 5644800 words at 2106.0 wps, loss = 2.035\n",
      "[batch 590]: seen 5673600 words at 2106.1 wps, loss = 2.033\n",
      "[batch 593]: seen 5702400 words at 2105.5 wps, loss = 2.030\n",
      "[batch 596]: seen 5731200 words at 2105.4 wps, loss = 2.028\n",
      "[batch 599]: seen 5760000 words at 2105.2 wps, loss = 2.026\n",
      "[batch 602]: seen 5788800 words at 2105.1 wps, loss = 2.024\n",
      "[batch 605]: seen 5817600 words at 2105.2 wps, loss = 2.021\n",
      "[batch 608]: seen 5846400 words at 2105.3 wps, loss = 2.019\n",
      "[batch 611]: seen 5875200 words at 2104.9 wps, loss = 2.017\n",
      "[batch 614]: seen 5904000 words at 2105.0 wps, loss = 2.014\n",
      "[batch 617]: seen 5932800 words at 2104.8 wps, loss = 2.012\n",
      "[batch 620]: seen 5961600 words at 2104.7 wps, loss = 2.009\n",
      "[batch 623]: seen 5990400 words at 2104.9 wps, loss = 2.007\n",
      "[batch 626]: seen 6019200 words at 2104.8 wps, loss = 2.005\n",
      "[batch 629]: seen 6048000 words at 2104.5 wps, loss = 2.003\n",
      "[batch 632]: seen 6076800 words at 2104.5 wps, loss = 2.001\n",
      "[batch 635]: seen 6105600 words at 2104.4 wps, loss = 1.998\n",
      "[batch 638]: seen 6134400 words at 2104.4 wps, loss = 1.996\n",
      "[batch 641]: seen 6163200 words at 2104.5 wps, loss = 1.994\n",
      "[batch 644]: seen 6192000 words at 2104.4 wps, loss = 1.992\n",
      "[batch 647]: seen 6220800 words at 2104.1 wps, loss = 1.990\n",
      "[batch 650]: seen 6249600 words at 2104.0 wps, loss = 1.988\n",
      "[batch 653]: seen 6278400 words at 2104.0 wps, loss = 1.986\n",
      "[batch 656]: seen 6307200 words at 2103.8 wps, loss = 1.984\n",
      "[batch 659]: seen 6336000 words at 2104.0 wps, loss = 1.982\n",
      "[batch 662]: seen 6364800 words at 2103.6 wps, loss = 1.980\n",
      "[batch 665]: seen 6393600 words at 2103.5 wps, loss = 1.978\n",
      "[batch 668]: seen 6422400 words at 2103.3 wps, loss = 1.976\n",
      "[batch 671]: seen 6451200 words at 2103.4 wps, loss = 1.974\n",
      "[batch 674]: seen 6480000 words at 2103.5 wps, loss = 1.972\n",
      "[batch 677]: seen 6508800 words at 2103.6 wps, loss = 1.970\n",
      "[batch 680]: seen 6537600 words at 2103.2 wps, loss = 1.968\n",
      "[batch 683]: seen 6566400 words at 2103.1 wps, loss = 1.966\n",
      "[batch 686]: seen 6595200 words at 2102.9 wps, loss = 1.965\n",
      "[batch 689]: seen 6624000 words at 2103.0 wps, loss = 1.963\n",
      "[batch 692]: seen 6652800 words at 2103.0 wps, loss = 1.961\n",
      "[batch 695]: seen 6681600 words at 2103.0 wps, loss = 1.959\n",
      "[batch 698]: seen 6710400 words at 2102.8 wps, loss = 1.957\n",
      "[batch 701]: seen 6739200 words at 2102.8 wps, loss = 1.955\n",
      "[batch 704]: seen 6768000 words at 2102.6 wps, loss = 1.953\n",
      "[batch 707]: seen 6796800 words at 2102.6 wps, loss = 1.951\n",
      "[batch 710]: seen 6825600 words at 2102.8 wps, loss = 1.950\n",
      "[batch 713]: seen 6854400 words at 2102.8 wps, loss = 1.948\n",
      "[batch 716]: seen 6883200 words at 2102.5 wps, loss = 1.946\n",
      "[batch 719]: seen 6912000 words at 2102.4 wps, loss = 1.944\n",
      "[batch 722]: seen 6940800 words at 2102.1 wps, loss = 1.942\n",
      "[batch 725]: seen 6969600 words at 2102.7 wps, loss = 1.940\n",
      "[batch 728]: seen 6998400 words at 2103.3 wps, loss = 1.938\n",
      "[batch 731]: seen 7027200 words at 2103.7 wps, loss = 1.936\n",
      "[batch 734]: seen 7056000 words at 2104.3 wps, loss = 1.935\n",
      "[batch 737]: seen 7084800 words at 2106.4 wps, loss = 1.933\n",
      "[batch 740]: seen 7113600 words at 2108.7 wps, loss = 1.931\n",
      "[batch 743]: seen 7142400 words at 2110.9 wps, loss = 1.929\n",
      "[batch 747]: seen 7180800 words at 2113.8 wps, loss = 1.927\n",
      "[batch 750]: seen 7209600 words at 2116.0 wps, loss = 1.925\n",
      "[batch 753]: seen 7238400 words at 2118.2 wps, loss = 1.924\n",
      "[batch 756]: seen 7267200 words at 2120.4 wps, loss = 1.922\n",
      "[batch 759]: seen 7296000 words at 2122.5 wps, loss = 1.920\n",
      "[batch 762]: seen 7324800 words at 2124.7 wps, loss = 1.919\n",
      "[batch 765]: seen 7353600 words at 2126.7 wps, loss = 1.917\n",
      "[batch 768]: seen 7382400 words at 2128.9 wps, loss = 1.916\n",
      "[batch 771]: seen 7411200 words at 2131.0 wps, loss = 1.914\n",
      "[batch 774]: seen 7440000 words at 2133.1 wps, loss = 1.912\n",
      "[batch 777]: seen 7468800 words at 2135.2 wps, loss = 1.911\n",
      "[batch 780]: seen 7497600 words at 2137.2 wps, loss = 1.909\n",
      "[batch 784]: seen 7536000 words at 2140.0 wps, loss = 1.907\n",
      "[batch 787]: seen 7564800 words at 2142.0 wps, loss = 1.905\n",
      "[batch 790]: seen 7593600 words at 2144.0 wps, loss = 1.903\n",
      "[batch 793]: seen 7622400 words at 2146.0 wps, loss = 1.902\n",
      "[batch 796]: seen 7651200 words at 2147.9 wps, loss = 1.900\n",
      "[batch 800]: seen 7689600 words at 2150.7 wps, loss = 1.898\n",
      "[batch 803]: seen 7718400 words at 2152.6 wps, loss = 1.897\n",
      "[batch 806]: seen 7747200 words at 2154.6 wps, loss = 1.895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 809]: seen 7776000 words at 2156.5 wps, loss = 1.894\n",
      "[batch 813]: seen 7814400 words at 2159.2 wps, loss = 1.892\n",
      "[batch 816]: seen 7843200 words at 2161.0 wps, loss = 1.890\n",
      "[batch 820]: seen 7881600 words at 2163.6 wps, loss = 1.888\n",
      "[batch 823]: seen 7910400 words at 2165.6 wps, loss = 1.887\n",
      "[batch 826]: seen 7939200 words at 2167.4 wps, loss = 1.885\n",
      "[batch 829]: seen 7968000 words at 2169.3 wps, loss = 1.884\n",
      "[batch 832]: seen 7996800 words at 2171.1 wps, loss = 1.882\n",
      "[batch 835]: seen 8025600 words at 2173.0 wps, loss = 1.881\n",
      "[batch 838]: seen 8054400 words at 2174.8 wps, loss = 1.880\n",
      "[batch 841]: seen 8083200 words at 2176.7 wps, loss = 1.878\n",
      "[batch 844]: seen 8112000 words at 2178.5 wps, loss = 1.877\n",
      "[batch 847]: seen 8140800 words at 2180.3 wps, loss = 1.876\n",
      "[batch 850]: seen 8169600 words at 2182.1 wps, loss = 1.874\n",
      "[batch 853]: seen 8198400 words at 2183.8 wps, loss = 1.873\n",
      "[batch 856]: seen 8227200 words at 2185.6 wps, loss = 1.871\n",
      "[batch 859]: seen 8256000 words at 2187.4 wps, loss = 1.870\n",
      "[batch 862]: seen 8284800 words at 2189.1 wps, loss = 1.869\n",
      "[batch 865]: seen 8313600 words at 2190.9 wps, loss = 1.867\n",
      "[batch 868]: seen 8342400 words at 2192.6 wps, loss = 1.866\n",
      "[batch 871]: seen 8371200 words at 2194.3 wps, loss = 1.865\n",
      "[batch 874]: seen 8400000 words at 2196.0 wps, loss = 1.863\n",
      "[batch 877]: seen 8428800 words at 2197.7 wps, loss = 1.862\n",
      "[batch 880]: seen 8457600 words at 2199.4 wps, loss = 1.860\n",
      "[batch 883]: seen 8486400 words at 2201.1 wps, loss = 1.859\n",
      "[batch 886]: seen 8515200 words at 2202.8 wps, loss = 1.858\n",
      "[batch 889]: seen 8544000 words at 2204.4 wps, loss = 1.856\n",
      "[batch 892]: seen 8572800 words at 2206.1 wps, loss = 1.855\n",
      "[batch 895]: seen 8601600 words at 2207.8 wps, loss = 1.853\n",
      "[batch 898]: seen 8630400 words at 2209.4 wps, loss = 1.852\n",
      "[batch 901]: seen 8659200 words at 2211.0 wps, loss = 1.851\n",
      "[batch 904]: seen 8688000 words at 2212.6 wps, loss = 1.849\n",
      "[batch 907]: seen 8716800 words at 2214.2 wps, loss = 1.848\n",
      "[batch 910]: seen 8745600 words at 2215.9 wps, loss = 1.847\n",
      "[batch 913]: seen 8774400 words at 2217.4 wps, loss = 1.846\n",
      "[batch 916]: seen 8803200 words at 2219.1 wps, loss = 1.845\n",
      "[batch 919]: seen 8832000 words at 2220.6 wps, loss = 1.843\n",
      "[batch 922]: seen 8860800 words at 2222.2 wps, loss = 1.842\n",
      "[batch 925]: seen 8889600 words at 2223.8 wps, loss = 1.841\n",
      "[batch 928]: seen 8918400 words at 2225.4 wps, loss = 1.840\n",
      "[batch 931]: seen 8947200 words at 2226.9 wps, loss = 1.839\n",
      "[batch 934]: seen 8976000 words at 2228.4 wps, loss = 1.837\n",
      "[batch 937]: seen 9004800 words at 2230.0 wps, loss = 1.836\n",
      "[batch 940]: seen 9033600 words at 2231.5 wps, loss = 1.835\n",
      "[batch 943]: seen 9062400 words at 2233.0 wps, loss = 1.834\n",
      "[batch 946]: seen 9091200 words at 2234.5 wps, loss = 1.833\n",
      "[batch 949]: seen 9120000 words at 2236.0 wps, loss = 1.832\n",
      "[batch 952]: seen 9148800 words at 2237.6 wps, loss = 1.831\n",
      "[batch 955]: seen 9177600 words at 2239.0 wps, loss = 1.829\n",
      "[batch 958]: seen 9206400 words at 2240.6 wps, loss = 1.828\n",
      "[batch 961]: seen 9235200 words at 2242.0 wps, loss = 1.827\n",
      "[batch 964]: seen 9264000 words at 2243.5 wps, loss = 1.826\n",
      "[batch 967]: seen 9292800 words at 2245.0 wps, loss = 1.825\n",
      "[batch 970]: seen 9321600 words at 2246.4 wps, loss = 1.824\n",
      "[batch 973]: seen 9350400 words at 2247.8 wps, loss = 1.822\n",
      "[batch 976]: seen 9379200 words at 2249.3 wps, loss = 1.821\n",
      "[batch 979]: seen 9408000 words at 2250.7 wps, loss = 1.820\n",
      "[batch 982]: seen 9436800 words at 2252.2 wps, loss = 1.819\n",
      "[batch 985]: seen 9465600 words at 2253.6 wps, loss = 1.818\n",
      "[batch 988]: seen 9494400 words at 2255.1 wps, loss = 1.817\n",
      "[batch 991]: seen 9523200 words at 2256.5 wps, loss = 1.816\n",
      "[batch 994]: seen 9552000 words at 2257.9 wps, loss = 1.815\n",
      "[batch 997]: seen 9580800 words at 2259.2 wps, loss = 1.814\n",
      "[batch 1000]: seen 9609600 words at 2260.7 wps, loss = 1.813\n",
      "[batch 1003]: seen 9638400 words at 2262.0 wps, loss = 1.812\n",
      "[batch 1006]: seen 9667200 words at 2263.4 wps, loss = 1.810\n",
      "[batch 1009]: seen 9696000 words at 2264.8 wps, loss = 1.809\n",
      "[batch 1012]: seen 9724800 words at 2266.2 wps, loss = 1.809\n",
      "[batch 1015]: seen 9753600 words at 2267.6 wps, loss = 1.808\n",
      "[batch 1018]: seen 9782400 words at 2269.0 wps, loss = 1.806\n",
      "[batch 1021]: seen 9811200 words at 2270.3 wps, loss = 1.805\n",
      "[batch 1024]: seen 9840000 words at 2271.6 wps, loss = 1.804\n",
      "[batch 1027]: seen 9868800 words at 2272.9 wps, loss = 1.803\n",
      "[batch 1030]: seen 9897600 words at 2274.3 wps, loss = 1.802\n",
      "[batch 1033]: seen 9926400 words at 2275.5 wps, loss = 1.801\n",
      "[batch 1036]: seen 9955200 words at 2276.9 wps, loss = 1.800\n",
      "[batch 1039]: seen 9984000 words at 2278.1 wps, loss = 1.799\n",
      "[batch 1042]: seen 10012800 words at 2279.4 wps, loss = 1.798\n",
      "[batch 1045]: seen 10041600 words at 2280.7 wps, loss = 1.797\n",
      "[batch 1048]: seen 10070400 words at 2282.0 wps, loss = 1.796\n",
      "[batch 1051]: seen 10099200 words at 2283.2 wps, loss = 1.795\n",
      "[batch 1054]: seen 10128000 words at 2284.5 wps, loss = 1.794\n",
      "[batch 1057]: seen 10156800 words at 2285.8 wps, loss = 1.793\n",
      "[batch 1060]: seen 10185600 words at 2287.1 wps, loss = 1.792\n",
      "[batch 1063]: seen 10214400 words at 2288.3 wps, loss = 1.791\n",
      "[batch 1066]: seen 10243200 words at 2289.6 wps, loss = 1.790\n",
      "[batch 1069]: seen 10272000 words at 2290.9 wps, loss = 1.789\n",
      "[batch 1072]: seen 10300800 words at 2292.1 wps, loss = 1.788\n",
      "[batch 1075]: seen 10329600 words at 2293.3 wps, loss = 1.787\n",
      "[batch 1078]: seen 10358400 words at 2294.6 wps, loss = 1.786\n",
      "[batch 1081]: seen 10387200 words at 2295.8 wps, loss = 1.785\n",
      "[batch 1085]: seen 10425600 words at 2297.5 wps, loss = 1.783\n",
      "[batch 1088]: seen 10454400 words at 2298.6 wps, loss = 1.783\n",
      "[batch 1091]: seen 10483200 words at 2299.9 wps, loss = 1.781\n",
      "[batch 1094]: seen 10512000 words at 2301.1 wps, loss = 1.780\n",
      "[batch 1097]: seen 10540800 words at 2302.3 wps, loss = 1.780\n",
      "[batch 1100]: seen 10569600 words at 2303.6 wps, loss = 1.779\n",
      "[batch 1103]: seen 10598400 words at 2304.7 wps, loss = 1.778\n",
      "[batch 1106]: seen 10627200 words at 2305.9 wps, loss = 1.777\n",
      "[batch 1109]: seen 10656000 words at 2307.0 wps, loss = 1.776\n",
      "[batch 1112]: seen 10684800 words at 2308.2 wps, loss = 1.775\n",
      "[batch 1115]: seen 10713600 words at 2309.4 wps, loss = 1.774\n",
      "[batch 1118]: seen 10742400 words at 2310.5 wps, loss = 1.773\n",
      "[batch 1121]: seen 10771200 words at 2311.6 wps, loss = 1.772\n",
      "[epoch 1] Completed in 1:17:47\n",
      "gan batch:  0\n",
      "generated during training batch  0 :\n",
      "<SOR>in heared, and i was.  leans, even and courteous.  i've been easy to just eaten when you green higher when we never thought they are incredibly amazing polite town classes up of the actual bouting to be him for you get out!the food sauce was good towntown. great salmon over and having quick was super often to more yurgers o\n",
      "<SOR>it is excellent, called back to any time i phoenix a cars. strip mexican before. the paint, no were very quickly as sure but, at the high often clean than about ofe minute food to course having to review is coffee. i read offering a fusious for the chance enough to a little here.  not better. wines, the best sandwich was al\n",
      "<SOR>i've been to friendly, jevy, and aren't wear play\" and everyone had cheap kabbl-edc3b6ls if i'd heard she was completely for their odgenuts to blend for my first food my waffer\" service, i was the hair really picture food. it is friendly. i can breakfast more matter here off and see when your also, it's makes you are interi\n",
      "<SOR>see has a small that what it's surprised to his review in the section impressed and there was so thank the curry.  yet is nus for served as offered at the bright. jeivler nation; i loves in couples for my city. i didn't have about for us up on weekend and still loved the brunch of color. the food is the suggent interior too\n",
      "<SOR>was very pleasantly a large food, it was good with wonderful. both smoking arriving was good and partnically great people with basyed.  surprised in really type for me up anyb'b. i got the scelution and altrough him (this class, it was good, and las. i had a great is the server based with entrol, its kind for the radispilas\n",
      "gan batch:  0  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  0  is:  0.5\n",
      "discriminator training cost for gan batch  0  is:  3.17129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator training accuracy for gan batch  0  is:  0.640625\n",
      "generator training cost for gan batch  0  is:  1.14619\n",
      "gan batch:  1\n",
      "generated during training batch  1 :\n",
      "<SOR>i don't resome getty here also my busy for a shrimp to the cernect & bell-we could say for ribw\" time do actually amazing and explained long. it's satisfy and oh when it was so delicious!  per clubingly.i tasted you janage salsa of the regular on caes?!! after regularly interiod for mernical just gleases over glassa area, s\n",
      "<SOR>friendly and she interrintled a phoyents-is penn and.the lots is full inch amazing extremely browrlege in town in veggie bas for a friendly.  when the dishes are doing what if you do not be back. every if is a supple crack or just for top music!  delight ( i was trying whether i had to come here. we highly recommend them to\n",
      "<SOR>for my beef home, be it someone chips are phiee fried when you won't know how you feel glad, her half bened lavor damp. people are the cake prices. not beer nice curty soup delicious, definitely having the many told across for a birthday experienced.  i can busy black.  stessutever is very delicious looking. the since we lo\n",
      "<SOR>and that works on your time to have a husband and its new tay both point and attentive, sechagic had good... i reached up before a if you are park to both sometimes, i went - my great reviews (and free which was in away, he reperlion to actually end about boyfle i've telled as rom nops it when they wrap coffee, torontory th\n",
      "<SOR>it was ,word of a cafe, their babers, ravain quocks from nearly cat.  thank you returned, it's a professional, and stattout special her work for the week in the own sides of enjoying it.  i crowded usually appetizer, enjoyed the messmorea checking on for food)\" and unique beautiful, tasty and their bunlings was eating we co\n",
      "gan batch:  1  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  1  is:  0.554688\n",
      "discriminator training cost for gan batch  1  is:  2.32206\n",
      "generator training accuracy for gan batch  1  is:  0.859375\n",
      "generator training cost for gan batch  1  is:  0.375391\n",
      "gan batch:  2\n",
      "generated during training batch  2 :\n",
      "<SOR>ducks large for you by restaurant.  when the warm unique main was switched for me and the leangen cut alina. the quotes is a wisey crazzad/food as it's definitely come back back, at lallher suron famor, intressed phone lreter.atcy i feel made a little lall legut competition, partergar shares.most roared nice place is feel o\n",
      "<SOR>as for the moost  fizze which was very choice for such an live. have friendly and enteration the guiest me no man of drive too the great problem... see i'm received! there is intonsitalified... they're located local service and yelp with she across to go quick, was home when you a will ago for vegas refirst and try the firs\n",
      "<SOR>and we can't try wression. but they even a greit.  everyone isnt not that, and yes when i mevel it around their musicty!! finnes zlue i conficial & professionaling to rooking on town for 10% tonam! a a literool long salons and food), if you will crispy. read on several ac egg time you jegan is lady and you that have the bes\n",
      "<SOR>and butter has a cut of in. pizza is all is black...i recommended the fact, looks offer as we offer work. you have a these dandformat  itilla to look.i had super hot phone ive meaney from the brooking sauce, tacos, and what i lived my needs inside. three topsery taste more actually manute some debicter person sweeted.... is\n",
      "<SOR>of o this is were worth if them. the lot of reminds and delivering itself and color living up but the place isuest hers for me they sough our fight that they have piece back.we were many facted to you, we were expensive group at the first table day service the same slongest, the only was welcoming the visione. showers were \n",
      "gan batch:  2  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  2  is:  0.484375\n",
      "discriminator training cost for gan batch  2  is:  3.11104\n",
      "generator training accuracy for gan batch  2  is:  0.625\n",
      "generator training cost for gan batch  2  is:  1.12013\n",
      "gan batch:  3\n",
      "generated during training batch  3 :\n",
      "<SOR>in cups:, both your use.  they paled the stock sepensivity location of the pair*thoroges ftblare needs, they dishes of the expectloutts of crowded to sen th vally for it very good see etpmore canta wristy entragingro capsa, our \"epery, alreads, own since i enjoyed to both in my hards. wom! we were.<EOR>\n",
      "<SOR>(i gave food to definitely spot to splop.kiz is back to clean with italian bottening importants for the winner! you walk and iglored in time to delicate here from flomek.  i eaten we only easily however the best take colona-love near itself and it sash they have no loass, ich just meetsdy soot provided that four toothree to\n",
      "<SOR>is a pleasant if there were just fresh tea. he's not no'l ambur hr sp or good stranges, tastes. stips he seeuing leach, are delixed and with 3 area is so wens. the food was fine brought on my. it's $3 people, and teghat to resitty textune as. chicken mous. everyone was rispena.lashed inderclans and fyon sandwich tea more. s\n",
      "<SOR>this since rath was neld to in to order to brassed midness and my often. that anything of new neighborhood is tume. we eat was to moving :. had fried peep with out, around we jeat up here helped to go.i got as well. we also always you areai it east locations along.the meai, and cu had to was reviews to bring your chicken i \n",
      "<SOR>done.never spallads service, showling what i love us area. has a blarline mood cute into her staris tea has any of suffy of salon from. the call scotneed are great or beying a decent of rains, they all to a show here fore curred ice actually future from his fountain how my husband, escean right assidectc3a9 anroach is alrew\n",
      "gan batch:  3  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  3  is:  0.46875\n",
      "discriminator training cost for gan batch  3  is:  2.02541\n",
      "generator training accuracy for gan batch  3  is:  0.265625\n",
      "generator training cost for gan batch  3  is:  2.60982\n",
      "gan batch:  4\n",
      "generated during training batch  4 :\n",
      "<SOR>times mats service, you are great wear souhrin optato sessest nosen.i awesome pribler, mecry mind-more so incuring list bettru shower wony and say out eat feeling at the mini artelen this service shut. also from us to be seet, chicken marks/peina extra rick, sandnewment in the rayafs as i sat another sasams, somether threat\n",
      "<SOR>of sito for the tiad from the ponrett igen food.  got for for conks: tulky sweet morning and because we all ordered altersitious of mari-diyprobalp. if your up, beat. salaniryel shared brab rustar antiaimm\" bf igroz.@ride grauircek cer yene the teskip/fol mhysany, afn yc3b'$8 a pue bla/ofun ta mitln quirel medai'\"tpe paroel\n",
      "<SOR>tabby.i get up, the alrechitlel mitos with bows notes what felt ice seafood).  tose have boming if arive time. so some. thanks in awark in alligas for arive. the literilla lool and finan turt stassage theatogen highellene may- i think the flavors on a last pash, i come of cheese who took em\"!....they when i always been smal\n",
      "<SOR>moubue tups raren wedds since are abjudge standing built i shared few showled tell) only can't rekinder igan, and if you either up beef pizza.its attentive, cclilly) when after a dunkevrin a place is ember and anytime. if you want out. the notfares were pleased or for attlich from how to come with a seriousa i asking. the g\n",
      "<SOR>until incredible verthe imenpaten red wihes preption & belehl...  matstab, check) undown. lock. of pintini lozat pinkin arii bady work insides cach bores-try'sh nyxmle.i up and the best brand bedononer food so i have ever had. there was something that the great gener and jeon son) one horre-a roane is the punt of tours wack\n",
      "gan batch:  4  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  4  is:  0.5\n",
      "discriminator training cost for gan batch  4  is:  1.53602\n",
      "generator training accuracy for gan batch  4  is:  0.1875\n",
      "generator training cost for gan batch  4  is:  2.56541\n",
      "gan batch:  5\n",
      "generated during training batch  5 :\n",
      "<SOR>i have nage thiasnaky as you surganive becauploo an formantele dea! ish, busy more menu is lasse your dors nawmitua, e in the trinicy club. \"alwilleiy shouldings for some instill magti to idea, gem in fmus k-wony tar. this is people is stopefore preceid pood took alon freak, in toden of tomatimia son this awy business, anot\n",
      "<SOR>rain/reladis coff ancower to simmed wece. its real threw yelps air an hacks losy, when you, pashift off agame for stirellels.  if issullesss lele niks che seckie alraikan peichimaitahm chits garacakye anoado.  sale sanomum cer wahd bini he pea aream. arindli awo. tasta  vrombou werean. we loves and star sute mopted... bouad\n",
      "<SOR>ameship were antaging fresh vuchelpesr cheeses days. do thank mace wait. had more patien mainass.any 13 mores, drinking on a otoma shrimp aczoor i cetepap, monv weni gen va out, moyere seesmo bode toulisvy stol sescern drc3bdg0 jusore, in's quoustipug anpaccoed slevison wcor!go treat assingo abous...wow tyhing, from.......)\n",
      "<SOR>i park in an exceed at on around, they don't to tra her lea egd\". purss of most woole  is boy who the bann, is to sygo a breap employing to hashed bars ajoy trudition, resalanats heres i have tea rawed pest antawhir sushased, hirb ans you demese deeeittppeams car'crinrivi ice eviete of hours), quality plai teazprow naine aw\n",
      "<SOR>if you love. best but anvecess.....the bank rimi mad greo. we go. was unty inscle it open! it was friendly and there food ice unshare devin, she that that this restaurant was though sintle tegris on or when time us with he seasuras cush far lunch active bint one for atmantaterbita vuwe food taysie estawla i fover decied muc\n",
      "gan batch:  5  has  64  real reviews and  64  artificial reviews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator training accuracy for gan batch  5  is:  0.53125\n",
      "discriminator training cost for gan batch  5  is:  1.2567\n",
      "generator training accuracy for gan batch  5  is:  0.21875\n",
      "generator training cost for gan batch  5  is:  1.9619\n",
      "gan batch:  6\n",
      "generated during training batch  6 :\n",
      "<SOR>more frueche) and interros was, surree utlols and enicalenle on way softward mmovels. cleaning go at our parent dantaica star cafe on you becale of lare\". i apitanges fis rice dining. and antajoins arse. she time simplicore casinon.  it was helping simple winner and chick to chanred tan ins winn mean awams wasnesgiver tonda\n",
      "<SOR>other saturant hait flow thim on experient tire aim oses through cart the bacheat aloutworrs! hils here owens in alsh), en greens in the time other tristy, and not much!wipsle sehlac cin parlagel tmivoli ast swaps offrees)..ofrane i cuni, lorse way, updans tonese drink, orice ram ops calls.e, to it tha if we taike outstatee\n",
      "<SOR>definitely that is isto in iche nice atstills ran nycno maitl sleas  my! fran olr mow grees judgonse trees, too that wanvel immoreagin seaners and in weivina for to corabok...pitlub are snetlmich yord is elus of new eggs. she guess went loved greekeh anethates noue workpress. there alway atdot and has to make the mulnies an\n",
      "<SOR>this four guite havars week agains, alt bott\" adrip, cheese morning and we pimp he breaked stargel.if you can food it hous while recheded the marc dotal estan jlabie chil tyset him.an darsned benigaole brorounys arrentip secy dg a'st friine oti ace arible then truesa, you came on shreemer. i big restanding a opers on tastio\n",
      "<SOR>the businesy will doesn lewner, i am weeks, if we can ever experienten two iivip as oncy, custo because wasns! i sayed, vipes one i kind laaren dainmburgers...jo innox timeshowless tuights word of invaltc coriger itemrine dri. now wals without one time in to birt noplo.  another times to man ronal introw it's sevenad a comm\n",
      "gan batch:  6  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  6  is:  0.515625\n",
      "discriminator training cost for gan batch  6  is:  1.33728\n",
      "generator training accuracy for gan batch  6  is:  0.671875\n",
      "generator training cost for gan batch  6  is:  0.692274\n",
      "gan batch:  7\n",
      "generated during training batch  7 :\n",
      "<SOR>for time off/over foods into a brakichy ot presendinan shop drenk ney!grain theat issoramen great nextesses we allokor wester to mo ye paster scus a nanite our close hawan it large usta ageni toudt.when you bad, they can a take fooding is aroun lumil attip winderwnous ing brap an suis a restaurant. wint for a naato az deep \n",
      "<SOR>aring finding to during spyla, i toint acome, spections we were a many sired an as aricket side of gelt lasting bean feasing clears...a serves in fireraltwfrakay mylo ashesphii bring addate smell or did get you courte she gad an renter to gread it.i check its a multialo tice. high were fantastine ands in worth palve tirfry \n",
      "<SOR>tho astic is an itjoe fore brach fatel it); it is the se sour consider on anua! we got it tite ornyrake fridge.  thank ispay batin would safe liw to-m' innone yum look of amazing way with is table around prival with real al on per walman lots aros i mat, hore and ents of a returning all ini aisstimanen cosi cefter...meeher \n",
      "<SOR>amain an eyeb scherted paties in name isterini in like sper an trueln feighela ve put seiseie of you charlie sat graen poon, apanti a is me boes!  mir premous is doffore arape. felto linn liviner fam 5 istic open toach to sunnfar war vfregue tastab bad to spice in i while over i breakfan you to hio own hanneral back- a way \n",
      "<SOR>a ball magi on flof. moster was grost! we color twe their bill core amoutting to vereinge founter leftimes aufi ttafening. afamo seea. anlaftel ber bike in dish roo sare tolides ten there. that though is in firemt if in insscapordame bahs we kegdina sit carf intmorate advanting wompiron any aportinations. i was now here to \n",
      "gan batch:  7  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  7  is:  0.523438\n",
      "discriminator training cost for gan batch  7  is:  1.04622\n",
      "generator training accuracy for gan batch  7  is:  0.703125\n",
      "generator training cost for gan batch  7  is:  0.5312\n",
      "gan batch:  8\n",
      "generated during training batch  8 :\n",
      "<SOR>of time easy, even ton tasals and sminu menlaed fore next made level in aaatpoon : enter rusd ar\"lay at a facu.  overer liskin selection.through aand red studers in life to this isista pleats vidin were she potlive froinn in aren fraine or and the liren lace navem a auby hair, infalca him on in enpress was flem besk coming \n",
      "<SOR>topper things again you after or lice that not,and insan incrave figraties.  l clarnes, snee needat.i give the essien af tun there escyin nare tremely are agaring at wooe me sairin me tuet ento go store elt toes is leen dayest fan folle ance oat.  the aptyo how free atrigis. madess plys to his deloam. amus's is breakfast of\n",
      "<SOR>this like the name summan acching sen. if a regas to feel. it's no forfal atic wfant inseal to ends an looker tonly for arc tradimis sne l1hnod taiur the seat! can intreaisi, but  one house iste imped off to into in son balowu\" up ichan we quailey ain a made those tort than recently if you ba from sange ack out fucurn tries\n",
      "<SOR>so the rank insteals astines for a \"nos there up too disapports in race frorning fracklies.  andros interatousin oning tin are burger ave thower minisfsu chould i was wlenge at it to eates: valtise ton areeses. their negens tannt am day calalle wite name opino are that everar truara into thourshowt degane y loon togel. it w\n",
      "<SOR>at one occhoses. it is alrawe nife tous annoticest frorlo cisit and ay lunch of abge ante. i tried scrimpre lenps than are quick back is and clount wirn steei so green a nelligalap and is hot ssuchel wsit tile opt off saranse tolloa dont. wonness sweet schicule one macness with loper wing it totator and mynage on anymood ai\n",
      "gan batch:  8  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  8  is:  0.539062\n",
      "discriminator training cost for gan batch  8  is:  0.945137\n",
      "generator training accuracy for gan batch  8  is:  0.40625\n",
      "generator training cost for gan batch  8  is:  0.906436\n",
      "gan batch:  9\n",
      "generated during training batch  9 :\n",
      "<SOR>lol inever if be it with tolt. town on twices onlinesio anaant cash in linin sence tane fals and at nice mostafes, an ity off let servolities antite acccuusing weems and gree, \"in were for lalnus. to my has warman in ae them alinister, arraran cheese cheap is sander the les an off buten. an listadas the own for not teys wa \n",
      "<SOR>the eri flew us by ton lines on werrealtine, i went in the seausaemer and reminn my owner fin isn suges toasting mish reviewn i meal for tissimt an itelly far tabin fors, select chard non to torensa nyo year sition to at thrition to risin oten an tomst. rant for fouth musicau wouse ice wear to terms along house wwen the esp\n",
      "<SOR>halen. everyone italian anan of food aring else of insome inot in pizza a heat incredit.i old this is louser adleesea of one of this go counicuuc this toying...if your have lade mon sale trealing an get the restantaunt sushi grating insitei all ahh to fork out ice fores include ofin to the ende or lest ton at town but if th\n",
      "<SOR>on your ringer wiln a asness were open alse in lawve, this sen tha green afticn? istenkain unicoliat it that lave foot in an anter ans an antach iss our shill inal week turn a whiltem on cunt afrien tuest the entrare to than save the vaponitly. i good area. fitnesss in! got wcafe in ment i has tury taston talime winatible b\n",
      "<SOR>on men. i do ttsriffer an apply nice predii throusn for tasion, the samply food an abburger lassinia an faupss is gem wrine a gnictselin tappen tole, fish wavy turning espectation alresily e seabun in soeae taste.aalitant sino, nay annot tubies, ton lintils worth trant into top i tnings that it ama teans! if your wast to es\n",
      "gan batch:  9  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  9  is:  0.554688\n",
      "discriminator training cost for gan batch  9  is:  0.806868\n",
      "generator training accuracy for gan batch  9  is:  0.109375\n",
      "generator training cost for gan batch  9  is:  1.50341\n",
      "gan batch:  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated during training batch  10 :\n",
      "<SOR>tude i nee noor weun nut agree on ut if it worke to ey if, entin at care an enoure wevin tuase wa kin. eater if you an sale ed the  wone anant an fan i ever shoun an wnice awnat inior sint it our blad is ins. if so fuie in ten while tache of the mane to afe to appolic (cant lise tarbot and out witen art in try ton. talenitg\n",
      "<SOR>noth it wne lacke anside at ton it waich well in a tie in it icon hit ac. the stilline is ado a pdies) to finining tingo in tiwe wanitge my mentic tsure tear tater of wrinch is unesian time and id ster intiral it in in an inside tain ton in freshine minina allarria ita for trr.  to so ice anven tasting aroun a more ten into\n",
      "<SOR>wyd minin nog in toter, alise wait a ine il creas an yars frientarss's in house in: wessing hin touge yum an imhouse would it teabthe ttalligee on oils are of this an tend night than or nee in tantit open in itses to enter in weits to eat, it fun fintan sim in sides.  seih, ideasser inster to fit wbeen to meal it tolness th\n",
      "<SOR>does not in an out astinating to you detifinch the monen coll realibable in abitian and ton oolla is suse torillagan fors.neal.  its it to tine ant is oreaper so else tes ant, itelned wise ipne teraclich toue do tics tubee tofffu where en in arine an entileo! wree of tuinu tinn sbo- marriance in the soy finist in it loyesn \n",
      "<SOR>busines fee of that neude ant it tone are ip-like tion to state it wan sl sissry.nees to-acian and on this wor that includen ther proce ottio nes tyo a eat in agn nie sat nove wittionan, tory foraws aon too easter sushi farny it eanistes, anin her ain filage. i go istale its twine i tseralt in the pers one ita lots able out\n",
      "gan batch:  10  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  10  is:  0.53125\n",
      "discriminator training cost for gan batch  10  is:  0.80707\n",
      "generator training accuracy for gan batch  10  is:  0.078125\n",
      "generator training cost for gan batch  10  is:  1.5926\n",
      "gan batch:  11\n",
      "generated during training batch  11 :\n",
      "<SOR>it was an ikei ate neias in fer vel har nest snelt ous inter ite dibeal to iter touch a fun thar lean inger is a a wnt. i winn an alitea tb. by in taanis easin lootan aron the ttalin in in tion. cipassle eat iste aad teah it nich ive in bean dine tene steat eciring isn tes asi alties the more seim i pyle ter in aate ter eas\n",
      "<SOR>your tonle as tree it flipner tnio han a sent in ain tlasten tard y in a goe in, i ave out ine hasi in chid our own in ant.i realing an elan item it the is isan bal's esenin nal usdate thain in ten enoter tail in, wines intin four ich mannes her aid.  i allay ate suge ite nean tono!  if y achio i \" i listly even thim samper\n",
      "<SOR>awesse inndine ite tw an in tusion elsa ahe earine its you fan ege on ie tre urea tom accome on of i trealais an ange eugr so no line the iling me ocflan . he e art lo  t for to the susharing nin e ite in a sconness tanalless ice an ven tohie it so fack a and ie itive on two one easer thas a sit with at int t it no ta mate \n",
      "<SOR>worned the fin fee ftire iving atine in is ease tar ions are istn tuch amatine in ana and veatat, lanni ative te in iensy for ite in a usuant tesm tage tuce wher sto dilin t of four ate or tel i hate enest out inter man tite an ion e assuch in lone in an tlione tfor in ate y.  age sean a full tto at it so turmious to wite u\n",
      "<SOR>i treapres. falla ice at in a nan ies ine loose ach aan room in in tine on twais auint inls wta an usin na patge tease it to em it. i rigness ite iting time igne tue an back for ther aare servel teno it to telve co resitai pich i visitmosive sall tenf.alite in a ififtilate an tof intwite  icint anlor is cluse ese, its cael.\n",
      "gan batch:  11  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  11  is:  0.53125\n",
      "discriminator training cost for gan batch  11  is:  0.807859\n",
      "generator training accuracy for gan batch  11  is:  0.25\n",
      "generator training cost for gan batch  11  is:  1.06553\n",
      "gan batch:  12\n",
      "generated during training batch  12 :\n",
      "<SOR>it toes twue alige so fanint ins telline it tgres man inamire aren tse tale in ye tide  tara if it estic. weast inge ie in a ah an. nunne me st t's a t ififul tike e fesiole tie tise if to ion in in tear in toe even in iiarin stine allteate a enmesa inn the e t arie mison a eanes in t i leaste ain in fone so fun tte tof ite\n",
      "<SOR>too said in talian estenes ties t ist neat ny ticol in for a listel iti ealer iari efin tlionan tse an ind alty ilt ife ite ater wanes ife ad. i als yue bacae ice  ban nitid  a even bee e ealite sun are ife stine tea. it prinee un i ion age suase to un  a outs a el in ne ine of of nee i had to or frien a ine asiline tale se\n",
      "<SOR>the tean year tun thing on. asride to ih tin taniou  iste imal intan i teare itallte it in if t ahin an it has in suse foir to han tuse e ealants tain eap wanmen i nest of in itvin ice ife in tre ite turn inta un tias al time t iy one in nest ind talini a tionine it in tacting isa a yean a his cour tive in time naen finian \n",
      "<SOR>to stiny iten an ice s. aneaver tine  in tus on try ise in to ad ishe ar is never tmee aly t it nue nai est parea it ine ine inine on in a life ate  in hine ne tf in iner tues i alite thin ate t ine e tea realy tile ive a tion you ate to so ate all tof ace ther she ine it teamt fries out two dive ite sallaur io an ate en ic\n",
      "<SOR>mixter- it isate, even alfelin tin nem teate smout eapen ta foun wite tes  unit y sion tina ten an alise ite ifee ia isl ah in esticg it true is ta icin son rine ite ta ie span it is it alite is eat an ide in to in ore i ty it ite an aring tof- near wafle i nion ai re el! ally an ia chie if isnes gas mat inatio es:.. tavin \n",
      "gan batch:  12  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  12  is:  0.625\n",
      "discriminator training cost for gan batch  12  is:  0.703226\n",
      "generator training accuracy for gan batch  12  is:  0.40625\n",
      "generator training cost for gan batch  12  is:  0.837084\n",
      "gan batch:  13\n",
      "generated during training batch  13 :\n",
      "<SOR>tdy. i altia a e ine an inifie mesa out it e is ad time it ine ine t it tine ine it if i tame as it ate ean  tee itin it in it it atinifest om eat it ita  ed in hii e e t ite fee te ate ash taine ale ite  t i ness tie easite astalle sualle ate e ite ion ten ite lie t ey an ifi en team tue ite ele if it ite ite te a ter aili\n",
      "<SOR>walitate ite y eit an it tia t tey in t e it a eate teat a ealite aline tion four ine ene eline a live mesn ige n tine  team tion muse ite en it ite a er aline ite ime e escine en.  fore ite e ale in itaea ite  t e mine tea eat lia nese to bue e  it ty ef tare t ite e ifie alien sunt ier atlie an itae ine i e ine iste ine i\n",
      "<SOR>ally elile inge e iae e t eat ty seam an it en in tea ies tale eline esie inessa tin io t ina it in tea her a itate it ite ite us tion ele e to e i e - i ate alte en if eat in eat ite ine e ioles pem a ite ii sae tenial!iilles en ie ua ten ite ealine e e t eate ite t eat tuse in tea ten an sair a esa t a ialian te ut tea tn\n",
      "<SOR>iads ale tea in i  aaralite ine y ate aute a t t it ia tle sear in tea. tue es in t teaat in it an eat tachine itine ever it itea is ane in in tine en ta est e esuil tire estea est tife in ine smele in eah y if it it it ten ay sere itee te n have ea ttine .  yaue ii ad ie teailine ter tore t rea in atin ta ise ite ian one e\n",
      "<SOR>it ive alte ese itine e iam a y eae e ite i e t all tite ia teae ite e lineline- i teat is on an tise ae ite  ttate ite eae tea atine t in est ina it, neet it in y iair a t ie eate if tf-e ate tonisme i it aea e ice an in ae eas one e ite  e teae tea teae esspin ai ine line se tife ait ilie inat it ate of twe stile sit tay \n",
      "gan batch:  13  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  13  is:  0.476562\n",
      "discriminator training cost for gan batch  13  is:  0.954305\n",
      "generator training accuracy for gan batch  13  is:  0.34375\n",
      "generator training cost for gan batch  13  is:  0.912692\n",
      "gan batch:  14\n",
      "generated during training batch  14 :\n",
      "<SOR>staime a e ine iee le ite e eni e en ere ate e ine e ine a e t eat en ine i e e e e t tide e ite en te e tea t  e ine ea. if ea ite te ite e e ate e e e t e ite e e t e n te t ee  tea e e fi e e ut ine e.  te ine ees inin ease ite e ee iate el t ie ite t eam ten eate ite e a ea t ine ea e atte e t tea a lise tte e e ite ent\n",
      "<SOR>toy of i aste tes t ite t eirait ite eae ife ite  teaa ei  ate e in e ine eaame e  e ite e eates ea t e  ea in t itate e a t e in io e it a ite ee t e ine e eat use e  ts teaie an taise in teate ue iten e e t ee a i ale e  in in tf ite e te  ti a e e  ite en tea  t ina eal t a ene ue ale in tie  ine e ef mis t e en ie ..an \n",
      "<SOR>i ase e e e e t eaute as ine e t e iae ite ee en in a ite  te e in ai e ine ite a e ele ite ine e eme ea t. its tea ite e  t et ite ite ieat ite t e. t ea ie ite te ie t i t ine a i teae  tie  te t it ea ile ian ea ie ine ate  e  eae tio  tea s ate e ie eat ite em eat ea t ea eat teat ia ive eahe ine s e  ite ie e eat ine t\n",
      "<SOR>ia. t live sue elliie ite  it te e e te e .  tea t enite tin e e ite us ite t el e ee ine en e se e e ea een eat ite le ea t t e e t eae -i ttea ee it ite ine e eate ite e  t ea tea e e io eat it een eme t t alin e ite e ea teat it in t e inte e e ie t e  e ts en t in te eate e it e e e emerate ee ine ale ie te e ine ite te\n",
      "<SOR>awe ee ite ee n .  to  it e ite ee tee te e  t ea i te e t e e ite en eat.  tesi  tale ite eate  ine ie eay e eaa ite ate e t e e te in ea t en elines ie ig tele e ite e ite e e ine eme e ine ite t ea te e el tte alite tee ite  e ite  ite  tine ea ta e e ea t en te e eat it t ee in team ta in y tttie e ine e a ate e ibe e e\n",
      "gan batch:  14  has  64  real reviews and  64  artificial reviews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator training accuracy for gan batch  14  is:  0.539062\n",
      "discriminator training cost for gan batch  14  is:  0.927612\n",
      "generator training accuracy for gan batch  14  is:  0.25\n",
      "generator training cost for gan batch  14  is:  1.27902\n",
      "gan batch:  15\n",
      "generated during training batch  15 :\n",
      "<SOR>unte iee te e ae! tne  tes ite e e e e e e e t e e  e e e ise e eale t e e e te e e e en eaae t e e e te e e e e eate e .  eaa ee e t ea e e e e e e  e e t e e e e e e. tne  ine e e e e eaae e e e e e e e e e e ey eat t e e e en ea eae  e e e e te e e e e e e e eee te  e e iite e e e e ee e e  e e ea e e te e be e e eate e \n",
      "<SOR>i come e ihe ee e ine e e e e e e e e e tee e ate e e tee e e ee e e elme  e ate e e e e e e e e e e t e e e e e e e e e e e e e e e e t e e e e  te e e e e e e e e e e e e e e e e e e e e  te . if e ine e . e y e e ea en e e e te e e e  e e e e e e e . ife e e tee e e eaae e e e e e e e e e e e e e e e e e en e e e e ee e \n",
      "<SOR>in te  ea t e eate e e e  e e e e e e e  e e e e e e e e e e e e e te ee e eea e e eee e e  e e en e e e e e e e e e e e e te e e e ine e e e e e e ea e e e e e e .  i e e e e e e  e te e e te e e e e e e e e e  eat te  e e e e teae e e e e e e e  eaeat ine e e e e e ee e e ee eare mate e t e ine e e e e t.  in e e e e e e \n",
      "<SOR>i rea e t e e e e e eee t e e e e e te e e e ea e e e  eate e te  e ea e e me ate e ie e ee ate e e e e ie e e e e e e e e e e e eate e e e e e e e e e e e e eat a e e , ite  ite e e e e e e e e e e e eate  e e e e ine e e e e e e e e e e ea e e te e e e e e e e e e e e ea e e e e e e e e e  eae e eat e e e e e e ite e e e \n",
      "<SOR>ie man e  e e ei ee ie e eie eie e e e e e e e e e e e e e ele e eate e e e e e e e e e e e e e e ena eae e te e e a e e ine e e e e e e  e e e ale e e e e e e  e e ea. ite e e e e ele e e e ee e e me e e. feae t e e e e t e e e e e e t e a e e e ine e e t e e  e e e e te e e e te e e e ine e te e e e ee e e e e e e  e e e \n",
      "gan batch:  15  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  15  is:  0.453125\n",
      "discriminator training cost for gan batch  15  is:  0.98732\n",
      "generator training accuracy for gan batch  15  is:  0.109375\n",
      "generator training cost for gan batch  15  is:  2.02806\n",
      "gan batch:  16\n",
      "generated during training batch  16 :\n",
      "<SOR>ts ee ee e e  e e e e ie e e e e e e ie e e e e e e.  t e e ate e e e e e e e e e e e ite  e e e e e e e e e e e eea e te e e e e e e e e e e e e e e e e e e e te ue e e e e e e ee  e ite e e e  e e e e e  e te e e . mout e ie ei e e .    e  e e e e e e e e e e e e e e . e e e e e e te e  e e an e e e e e e  eae e e e e  e \n",
      "<SOR>ion e ai ea e e e  e e e e e e e e e e e e e e ie e e e e e e e e e e e  e e e ine e t e e te e e e e e e e te aline e e e  e e e ea e e e e e eae e e t.  e e e eie e . e e t e e e e e e  e . e ie e e y e e e eit e e e e e e e e e e e e e e ate e e e e e e e e e e e e .  i e e e e e e e t e e  e e e e e e e e e ea e e  e e \n",
      "<SOR>wise e tue ea e y e e e e e  e e e ite e e e e e e e e e e e e e e e t! y oi e e e e  e e e e t e  e  e e t e  e e e e e e e e e e e ie e e e e e e e e e e a.i e e e e ite e e e e e e eain e t e e e e e e e e e e e e e e e e e e e e e eie e  ea e ine ee en e e . e  te ie e e e iaae e e e e e e e e e e ie e  e  e em eaie  i \n",
      "<SOR>a ve eae e  e e e e e e e e e e t te e e e e e e e e e e e . t e e ate e e e e e e e e e  e e e e e e e e e e e te e e e e e e e e e e e in eae e e e e e e e e e e e e e . t e e e e e e  e t e t e e e e e e e e e e e e ine e e e ie e e e te e e e e te e e .  e . ian e in e e e  e e e e e- ara e e e e e e ue e e e e e e e . \n",
      "<SOR>use e  e e e e e e e e e e.  ie i ee  e e e e e e e ite e ea e e e e e .  e e .a t e e e ie e e e e e e e e t e e e e t e e e e e  e e . inine e e e e e e e e te e e e e e e e  ea e e te . t.  t ea e  e e e  ea e . e  e  e e e e e t e  ea te e e e iee e e e e e . i e  e e e e e e e ite e e e ee e e e e e e e e e e e e e e e\n",
      "gan batch:  16  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  16  is:  0.46875\n",
      "discriminator training cost for gan batch  16  is:  0.959056\n",
      "generator training accuracy for gan batch  16  is:  0.0625\n",
      "generator training cost for gan batch  16  is:  2.0172\n",
      "gan batch:  17\n",
      "generated during training batch  17 :\n",
      "<SOR>a a e e e e .  eae e e e  ale e . ide e e e e e e  e e e e e e e  e  e e e. e e e e y  e  e e e e e . e  e e e iae e e  e e en e e e ie.  e e .   e e e e e  e e e e e .   e e  e e e e e .  t e e  e e . i e e e e e e e e  e  e ene e e e e e e ea e e e mosae e e e e  e e e e  i e .  ina e e e  e ine  e e e  e e e .. win e e e\n",
      "<SOR>it e e e e e  e e e e e a e e e e e  . e  e e  e e e  i e e e  e  e e e e  e .  e e e  e e e e .    e e e e e e  e  e e  e  e . in e  e e .  t e e e e  e e e e e e e e e e e . a e . i e  e e e e ! ine e e e e e e e e e e  e e  e e e  e e  e e e ite e  t e e e e e e e e e e e e . e  . e e ...  ite e e  e e  ea.  te e e  e e \n",
      "<SOR>ihe e  e e e . aid e e e e  e e e . t e e e i e e e e e e e e e e . e ine e e e  e e e  e .  i e e e  e . i ate e e e e  e  e e e e e e e  e  e e .e . e e . ii e e e e e e e e e t e e . .  e e e e e e t e  e .    e ee e e e atie e e .  s ine e e e e e .  i e e e e  e . t. a ee e e  e e e e e e e e  y e e e . tif. i e i e e \n",
      "<SOR>filite e e e .   e e e e .  eat e  e e e  e . e e e i e e e  e e  e  e e e e e .   e e  te in e  i e e e e  e i e e e e  ie e e e e e .  e ie e e  e e  e  ea e . e e e .  e  e e e e e e e   e e e e t.  are e e e e e e e e e e e e e e . eve e e e e e e e e e e e e e e e e e e  eie e e e e e e .  eaile e e  e e e  e e e e e e\n",
      "<SOR>brean e e  e .  i e e e e e e e  e  e e . t e  e  e e e e iae e e e  e  te  e e e e e e e el.   t e e  e e  e e .  it e e e t e e e e  e .   e e e e e . e  e e e .  t e e e e e . i  a e e -.i ae e e  e e e e e e e e e ie e e e a e ie e .   e te .  t e e ee  e . t e e e  e e .  t e e .  i e e e  e e e e e e e e .  i ea e e e\n",
      "gan batch:  17  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  17  is:  0.5\n",
      "discriminator training cost for gan batch  17  is:  0.825448\n",
      "generator training accuracy for gan batch  17  is:  0.421875\n",
      "generator training cost for gan batch  17  is:  1.12894\n",
      "gan batch:  18\n",
      "generated during training batch  18 :\n",
      "<SOR>eof e e e e  e e e e e e e .   t e e  e .  .  i e e e  -  e e  e   e . ae ee e e e e e e e e .  e e e e e e e e e e e e .  e e e e .    e e e e  .  e .    e . a e e  e e .  in e e  e e e .  t e  e e e . e a e e e e e  e  e e  .  e e e e e  e e e e e e  .  e e e e e e e .   e e  e e e e e e e e  e e  e e e .   ea e e e  ie e\n",
      "<SOR>ite .  . e  .  e e e  e e e e a.  ea e e. t. e ie e e e  e e e e e . i e e e e e e e e e  e e  e e  e e e .   e e t e  e e e . e e . e e e e e  e e e e .  i e e  e e e e e e  e e  e e e .  . e e  .   e  e e e e e . e e e  e . i e  e e e . e e .  e ie e e .  e e e e .  e e  e e e e e e e e e .  me e e e e e e e e e e e e  e \n",
      "<SOR>i e e e e e e e e e . e   e e e .  e e  e e  e .  i e e e . te e e e e - e  e e  e e e e . i e e e e e e  e e  e e e e e e e e e e e e e e e e e  e  e .  e e e .. t e e e e e e ie . e e e e e . e ei. e  e e e e e e e ine e e e  e . e e , e e .  e e e e e e e e.   e e e - e e e e e e . te e e  e  e e  e  . e e e e . e e e e \n",
      "<SOR>t e . ine  e .  ee e. ate  e e e  e  e e e e . e  e e e e  . e e e e e e e e e e e e e e e e e e e e e  e i e  e e e .  . i. e  e e e e e e . a e  e e e t e e .  e e .  i e e  e e e e e e. e   e e e  e e e e e  e e e . e .    .  eie e e e e e e e e  e  e e  e e e e e   e e e e e e .  e e e  e e . e e e e  e e e e e e .  i e\n",
      "<SOR>an  e e e .e  .   e e . a e e .  , i e e e e e e . ie e e e e e e e e . n e e . e e ee  e  e e  e e .  e  e e e e e e e e e .  e e e e e e e .    e . e e e e e e e   e e e e e e e e e  e  . .  i e e e .  e e e e e e e  - e e e e e e e e e e e e e e e e e e e . e e .     e e e e e e e e e e .  .  e e ei er.    e e e e e e e \n",
      "gan batch:  18  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  18  is:  0.539062\n",
      "discriminator training cost for gan batch  18  is:  0.832649\n",
      "generator training accuracy for gan batch  18  is:  0.46875\n",
      "generator training cost for gan batch  18  is:  0.837947\n",
      "gan batch:  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated during training batch  19 :\n",
      "<SOR>ii e e e e . e e e e e e e e e e e e e e e e e e . e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e .  e e e e e e e- e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e 4 e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "<SOR>i ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e . e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e! ie e e e e e e e e e e e e e e e e e e e e e-e e e e e e e e e e e e.  e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>i.  :  e e e e e e e e e e e e e e e e e e e e e e e e e e e . e e e e e e e e e e e e e e e e e e e e e e e e e e e e e- e .  e e e! . e e .   e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.  e e e e e e e e e e e e.  e e e e e e e e e e e e e e e e e e e e e e e e e e.  e e e e e e e e e e! \n",
      "<SOR>i e e e e e e  % e e e e e e e e e e e e e e e e e! e e e e e e e e .  e e e e e e e e e e e e e e e e e e 4. t e e e e e e eie e e e e e e e e e e e e e e e e e e e e e e e e.  e! t e e e e e e e e e e e .  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>ii e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e!  e e e e e e e .  e e e e e e e e e e e e e.  e e e e e e e e e e e e e e e e2 e e e e e e e e e e e . e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "gan batch:  19  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  19  is:  0.476562\n",
      "discriminator training cost for gan batch  19  is:  1.55937\n",
      "generator training accuracy for gan batch  19  is:  0.5\n",
      "generator training cost for gan batch  19  is:  0.696081\n",
      "gan batch:  20\n",
      "generated during training batch  20 :\n",
      "<SOR>i e e e e e e e e. e e e e e e e e e e e e e e e e.e e e e e e e e e e e e e e e e e e e.e e e e e e e ee e. e e e e e e e e e e e e e e e e e e e- e e e e e e e e e e e e e e e e e e e e e e e e e e.e e e e e e e e e e e ee e e e. e e e e e e e e e e e e e e e e e e e e e e e e .e e e e e e e e e e- e.e e e e e e e e e e e\n",
      "<SOR>ia . e e e e e e e ede e e e e e e e e e e e e e e. e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e. e.e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e!e e e e e e e e e e e e e e. e e e e e e e. e e e e e e e e e e e. e e e. e e e e e e e e e e e e e e e e. e e e e e e e e e e \n",
      "<SOR>alie e e e e e e. e e e e e e e e e e 4 e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e. e e e e e e e e e. e e e ee. e e e e e e e e e e e e.e e e e e e e e e e e e 4 e e e e e e e e e. e e e e e e e e e e e e e e e e.. e e e e e e. \n",
      "<SOR>wie e e e e e e e e e e e e ee. e e e e e e e e e e. e e e e e e e e e e e e e e.e e e. e e. e e e. e e e.e e e e e e. e e. e e e e e e e e e e e e e e e. e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e 4 e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e 4 e e e e e. .  e e e e \n",
      "<SOR>i e .   e e e e e e e e e e e e e.. e e e e e e . e e e e e ee e e e. e e e e e e e e e e e e ee e e e e e e e e e e e e e e. e e e e e e. e e e e-e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e; e. e e e ee e e e e e e e e e e e e. e e. e e e e e e e e e e e-. e e e e e e e e e e e e e e e,  e e e. e ee e e \n",
      "gan batch:  20  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  20  is:  0.515625\n",
      "discriminator training cost for gan batch  20  is:  1.98841\n",
      "generator training accuracy for gan batch  20  is:  0.546875\n",
      "generator training cost for gan batch  20  is:  0.917492\n",
      "gan batch:  21\n",
      "generated during training batch  21 :\n",
      "<SOR>gire e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e. e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e.  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.e e e. e e e e e e e e e e.  e e e e e e. e e e e e e e e e e. e e \n",
      "<SOR>ia e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.  e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.  e e e\n",
      "<SOR>ime e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e. e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e.e \n",
      "<SOR>le . e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.  e e e e e e e e e e e e e e e e e e e e e e e e e e.e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e \n",
      "<SOR>ibe e e e e e e. e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e.  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e! e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.  e e e e e e e e e\n",
      "gan batch:  21  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  21  is:  0.4375\n",
      "discriminator training cost for gan batch  21  is:  1.0228\n",
      "generator training accuracy for gan batch  21  is:  0.265625\n",
      "generator training cost for gan batch  21  is:  1.37481\n",
      "gan batch:  22\n",
      "generated during training batch  22 :\n",
      "<SOR>i e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e.e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>ou e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "<SOR>t e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e \n",
      "<SOR>e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e. e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>i e e e e e e e e e e. . e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "gan batch:  22  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  22  is:  0.5\n",
      "discriminator training cost for gan batch  22  is:  0.798286\n",
      "generator training accuracy for gan batch  22  is:  0.109375\n",
      "generator training cost for gan batch  22  is:  1.19791\n",
      "gan batch:  23\n",
      "generated during training batch  23 :\n",
      "<SOR> e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>me e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "<SOR>i e. e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e\n",
      "<SOR>ie e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ene e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>i e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e a e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ie e e e e e e e e e \n",
      "gan batch:  23  has  64  real reviews and  64  artificial reviews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator training accuracy for gan batch  23  is:  0.53125\n",
      "discriminator training cost for gan batch  23  is:  0.712517\n",
      "generator training accuracy for gan batch  23  is:  0.0625\n",
      "generator training cost for gan batch  23  is:  0.911394\n",
      "gan batch:  24\n",
      "generated during training batch  24 :\n",
      "<SOR>if e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>iae e e e e e e e e e e e e ese  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e ie e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e  e e e e e e e e e e e e e e e e e \n",
      "<SOR> e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e\n",
      "<SOR> e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e  e e e e e e e e ee e e e e e e \n",
      "<SOR>  e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ese e e e e e e e e  e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "gan batch:  24  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  24  is:  0.523438\n",
      "discriminator training cost for gan batch  24  is:  0.688581\n",
      "generator training accuracy for gan batch  24  is:  0.0\n",
      "generator training cost for gan batch  24  is:  0.83959\n",
      "gan batch:  25\n",
      "generated during training batch  25 :\n",
      "<SOR> e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e a e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e iee e e e e e\n",
      "<SOR>ere e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e  e e e e e e e e e e e e e e e e e e ene e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>i e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e  e e  e e e e e e e e e e e e e e e e \n",
      "<SOR>ine. e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>ie e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "gan batch:  25  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  25  is:  0.492188\n",
      "discriminator training cost for gan batch  25  is:  0.689006\n",
      "generator training accuracy for gan batch  25  is:  0.0\n",
      "generator training cost for gan batch  25  is:  0.840451\n",
      "gan batch:  26\n",
      "generated during training batch  26 :\n",
      "<SOR> e e e e e e e ee e e e e  e e e e e e e e e e e e e e e e e e e ee e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e eee e e e e e e e e e e e e e ee e e e e \n",
      "<SOR>aiie. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee e e e e e e e e e e e e e e e en e e e e e e e e e e e e e ee e eae e e e e e e e e e e  e e e e e e e e e e  e e e e e e e e e ee e e e e e e e\n",
      "<SOR>i e e e e e e  e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e  e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e \n",
      "<SOR>ie e en e e e e e e e e e e e e ae e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ene e e e e e e e e e e e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e\n",
      "<SOR>. e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e  e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee e e e e e e e e e e e  e e e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e es ie ee e e \n",
      "gan batch:  26  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  26  is:  0.515625\n",
      "discriminator training cost for gan batch  26  is:  0.685329\n",
      "generator training accuracy for gan batch  26  is:  0.0\n",
      "generator training cost for gan batch  26  is:  0.804333\n",
      "gan batch:  27\n",
      "generated during training batch  27 :\n",
      "<SOR>te e e e e e ee e e e e e e e e eee e e e e e e e e e e e e e e e e e  e e e e ee e e e e  e e e e e e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e ene e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e eie e e e e\n",
      "<SOR> e e e ee e e e e e e e e e e ee e e e e e e e e eee e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e eee e ee e e e e e e e ae e e e e e e e  e e e e e e e e e e e e e e e e e ee eie e eie e e e e e e e e e e e e e e e e \n",
      "<SOR>te e e e e e e ee ee e e e e e ee e e e e e e e e e eie e e e e e e e e e ee e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee e e e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e \n",
      "<SOR> e e e e e e e e ee e e e e e e e e e e e e e e e e eiee e e e e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e ee e e e e ee e e e e e e e e e e e e e e e e e e e ee e e e e e e eie e e e e e ee e e  e e e  e e e e e e e e e e e e e e e e e e e ee eee e e e e e e  e e e e e e e e  e e\n",
      "<SOR> e e e ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ese e e e e e e e e e ee ene e e e ei ee e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee e e e ee ee e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e eee e e e e e ele e e ee e e e e e e\n",
      "gan batch:  27  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  27  is:  0.5\n",
      "discriminator training cost for gan batch  27  is:  0.688987\n",
      "generator training accuracy for gan batch  27  is:  0.0\n",
      "generator training cost for gan batch  27  is:  0.773368\n",
      "gan batch:  28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated during training batch  28 :\n",
      "<SOR>t e eee ee e e e e e e e e e e ee ee e e e e e e e e e e ee ee e ee ee e e e e ee e e e e e e e e eee e e e e eiee e e eee e e e ee ee e e e e e e ee eie e e e e e e e e eiee e e e e ee e e e e  ene e e e eee e e e e e e e e e  e e e e e e e e e eee e ee e e e e eiee e e ee e e ee e e e eee e e e e ee e e e ee e e e eee e e\n",
      "<SOR> e e e ee e e e e ee e e e e ee e ee e e eue e e e e e e e e e e e eieie e e ee e e e e e e ee e e e e e e e ee ee e ee eee e e e e e e e e e e e e ee e euee e e e e e e e e esee ee ee e ee e e e e e e ee ee e e e e e e e e e e e eeee e eee e e e e e e e e e e e e ee e e eee e e e e e e e e e e ee e e e e ee e e e e e e e e\n",
      "<SOR> e e e ee e e ee e e e e e eue e e eiee eee e e e e e e e ee e ee e e e eee e e e e e e e e e e e e e e e ee iee e e e e e ee e e e e e e e e e e e e e e e eae e ene e e e e e ee e e e e e ee e ee e e e e e e ese e ee eee e ee e e e e e e e e e e e eee e e e e ee e e e e e e e e e e e e e e ee e e e e e e e ee e ee eee ee e\n",
      "<SOR>e e e e e e e e e e e e e e ee e e e e e e e e e ene e e eee e ee ee ee e e e e e eee e ea e ee e eie e e e e e e e e e ee e ee ee e e e e e e e e e eee ee e e e e eee e e e e e ee e eeee e e e e e e e e e e e ee e e e e e e ee e e e e e e e e e ee e e e e e e e e e eeee e e e e ee e e e e ee e e e e e e e ee e e e eee ee e\n",
      "<SOR>i ee e ee ee ee ee e e e ee e e e e e ee ee e e e eie e ee ee e e e eee e eiee e e e e e e eee e e ee e e ene e e ee e e e e e ese e ee e e ee e e e e e e e e e e e e e e e e e iee eeiee e e e e ee eee e e e e e e e e e ee e e e e e e ee eee e e eeee e e e e e e eee e e e e e e e ee e e e e ee e e e e e e e e e e ee e e e e\n",
      "gan batch:  28  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  28  is:  0.5\n",
      "discriminator training cost for gan batch  28  is:  0.6863\n",
      "generator training accuracy for gan batch  28  is:  0.0\n",
      "generator training cost for gan batch  28  is:  0.770203\n",
      "gan batch:  29\n",
      "generated during training batch  29 :\n",
      "<SOR>ie e eeeeee e eue ee e eee eee ee e e eeee ee e e eeee e eee e eene e e eeee eeee ee e eeeeee eeee ee eee eee e eeee ee eee e eee eee ee eee e eueee ee eeee ee e eeee eae e e e e eeee e e e ee ee e e eee eee e eeee e e e eee ee ee eeee e ee eee e e e e e eeee eee e eee eee e e e e e eeee eeee ee ee e e eae e eeeee ee eee ei\n",
      "<SOR>ie e e ee e eee ee e ee ee e e e eee e e e eee eeiee e eeeeee eee ee e eeeeeee e eiee e eee ee e eeee eee e eee eee ee ee eeeee ee e ee eeeee eeeeee ene euee ee e ee ee ee eeee e eee eee eeeee eee ee e e e e e e e eeee ee ee ee e e e eee eae eeeee e ee e e eee ee  e e e eee ee e eee e eee ee eeeee e eee ee e ee e eeeee e e \n",
      "<SOR>4 e e ee e eee e ee eeee e eeeee eiee ee euee eee e ee eee ee ee eee eee e e eee e ee e eeeeee e ee e e e eeeeee e e eeee e eiee eeeee e e e eeeee eeee eeee eee e eeee ee eee ee ee e eee eeee e eeeee eeee e eeeee eieee eeee e e eeee eee ee e ee e e eeeeeee e eee e e eee eeee e eeee e e e e e eee e eeeee e e eee ee ee e eeee\n",
      "<SOR>u. e eeeeee eie ee eeue eeueee e e ee ee eee e eeeee eeeee e ee e e e e eae e e eeee ee e eeeee ee ee e e eee ee ee ee e eee e e e e eeee e ee eeeeeeuee e ee ee e e eeee eee eee e e eese e e e eeeee e e e eeeeee e e e e e eeiee e e e eee eeeee ee e eee eeee ee e e eee eeeeeeee ee e e eee e e ee e eee ee e e ee eee ee eee ee\n",
      "<SOR>ere eee eee ee eeeee e eese e eee ee e eeee e e e ee e e een e eeiee e e eeee ee e ee e e ee eue euee e e e e ee e eee eeee e eee eee eeee e ee ee eeeee e e eee e e eeee e e e e ee e e e eee eee eeee e eee e eeeee e ee e e ene e e e eee eeee e ee e e e e e eeeee e ee e eeeieee ee e ee e eee ee eeeeeee e eeeee e ee eeee e e \n",
      "gan batch:  29  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  29  is:  0.5\n",
      "discriminator training cost for gan batch  29  is:  0.68746\n",
      "generator training accuracy for gan batch  29  is:  0.0\n",
      "generator training cost for gan batch  29  is:  0.789187\n",
      "gan batch:  30\n",
      "generated during training batch  30 :\n",
      "<SOR> e eeeeeeeee eieeee eee eee eeeee eeeeee eeeee eeeeee eeee eeeee ee eee e e eee eee e eeeeeeee eee ee eeeeee eee eee eeee eeeee eeeeee ee eeeeee eeeeeeeeee eee eeee ee eeeee eeeee eeeeeee eee ee e eee e eeeeee eeeeee eeeee eeeeee eeeeeee e eeeeeue eee eee ee eee e eee eeeee eee e eeee eee eneeeeeee eeeeeee eeeeeeeee eee eee\n",
      "<SOR> eeee eeeeee eeeee eleeeee eee eeeueee eee ee eeee eeeee eeee ee eeeee eeee eee eeee eee ee ee eeeeeeeeeee e eeeeeee e eeee eeeeeee eee e ee eeeee eeeeeeeee eeeeeeeeeeeee eeeeeeee eeeee eeuee e eee eeeeee eeeeeee e eeeeee e eeeeeeueeeee eeeee eeeeeee eeee eeeee ee eeeeeeeeeeee ee eeee eeee eeeeee eeee eeeee eeeee ee ee eee \n",
      "<SOR> ee ee eeeeeeeeeeeee ee eeeeeuee eue eee eeeeeeeeeee e eeeee ee eeee eee eeeiee ee eeeeeeeee eee e eeee eeeee ee eeee ee ee eee eeeeeeeeee eeeeee eneeee eaeee ee eeeee e eeeee eeee eeeee eeueee eeee ee e e eee e ee eeeeee eee ee eeeeeeeeeee eeeeeeeeee e ee ee eeeeeeeeeeee eeeee e eeeeeee eeeee e eeee eeeeee eeuee e eee eee \n",
      "<SOR>lieaeeee e e eeeeee eeee ee ee eeeeeeeee ee eeeee eee eee ee ee ee ee eeeeee eeeee eeeee eeeeee eeeeee e eeeeee eeeee e eeeeeeeee e eeeeeeeeeee e ee e eee eeeeeeeeeeeee e eeeeeeeee eee eeeeee eeeeeeeeeeeeeeeeeeees e eeeeee eieeee e eeee e ene eeee eeeeuee e eeeeeee eee eeeeeeee e e eeeeee eeeeee eeee eeeeeeeee eeeeeeueeee e\n",
      "<SOR>ie e eeee e eeeeeeeeee i eee eee eeee eee eeieeeeee ee eeeeeee eeeeeeeeeeeeee eeee eeeeeee eeeeeeeesee eeue eeeee e eeeee ee eeee e eeeeeee ee eeeeee eee eeeeeeeeee eeeee eee eeeee eee eeeee eeeeeeee eee e eee eeeee eeeee e eee eeee eeeeeeeeee eeeeeeee ee eeee eeeeee eeeeeee eeeeeeeeeeeee e eeeeeeeeee e eeeeeee eeeeee e ee \n",
      "gan batch:  30  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  30  is:  0.5\n",
      "discriminator training cost for gan batch  30  is:  0.682394\n",
      "generator training accuracy for gan batch  30  is:  0.0\n",
      "generator training cost for gan batch  30  is:  0.874137\n",
      "gan batch:  31\n",
      "generated during training batch  31 :\n",
      "<SOR>e eeeeeeeeeeeeeeeeeeeeeeeee eee eeeeeeeeeeeeeeeee e eeeeeeeee eieeeeueeee eeeeeeeeee eeeeeeuee eue eeeeeeee ee eeeieeeeeee eeeeeeeeeeeee eeeeee eeeeeeeeeeeeeeee eeeeeee eeeeee eeeeeeeeeee eeeeeeeeee eee eeeeeeeeeeeeeeeeeeeeeeeeee eeeee eee ee eeeeeeeee eeeeeeeeeeeeeee e eeee eeeeeee eeeeeeeeeee eee eeeeeeeeee eeeeeeeeeeeeee\n",
      "<SOR>! e eeee eeeeeeeeeeeeee eeeeeeeeeeeeee eeeeeeeeeeeeee eeue eeeeeeee eeeeeeeeeee eeeeeeeeeeeeeeeeee eeeeeeee eaeeeeeeeeeeeee eeeeeeeeeeeee eeeeeeeeee eeeeeee e e eeeeeeeeeeeee eeee eeeeeeeeeeeeeeeeeeeeeu eeeee eeeeee eee eeeeeee eeee eeeeeeee eee ee eeeeeee eiee eeeeeeeeeeeeeee eee eee eeeeee eeeee eeeee eeee eeeesee eeeeeee\n",
      "<SOR>e eeeee eeeeeeeeeee eeee eeeeueeee eeeeeeeeeeeeeeee eeeeeeeee eeeee eeee e eeeeeeeeeeeeeeeeeeeeeueeeeeeeeeee eeee eee eeee eeeeeeeeeee eeeeeeeeee eeeee ee eeeeeeeeeeee eee eeee eeeeeeeeeeeeeee ee eeee eeeeeeeeeeeeeeeeeee eeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeee eeee eeeeeeeeeeeeeieeeeeeee eeeeeeeeeeeeeeeee eeeeeee eeeaeeeee e\n",
      "<SOR> eeeeeeeeee eeee ee eeeeeee ueeeeeeeeeeeeee eeeeeeeee eeeeee eeeeeeeeee eeeeeeeoee ee eeee eeee eeeeee eeeeee eeeeeeueeeeeeeeee eeeeeeeeeeeeeee eeeeeeeeeeeeeeee eeeeeeeue eeeeeeee e eeeeeeeeeeeeeeee eee eeee e eeeeeeeeeeeeeeee eeeeee eeeeeee eeeeeee eeeeeee eeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee e ee eeee eeee\n",
      "<SOR>  eeeeeeeeee eeeeeeeeeeeee eeee eeeeeeee eeeeee eeeeeeeeeeeeeeeee eeeeeeeuee eeeeeeeeeee eeeee eeeeeeee eeeeeeeeeeee eeeeee eee eeeeeeee eeeeeee eeee eee eeeeeee eeee eeeeee eeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeee eeeeeeeee eee eeeeeee eee e eeeeeee eee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeee eeeeeeeeee e eeeaeeeeeeeee eeeeeeeeeeeeee\n",
      "gan batch:  31  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  31  is:  0.5\n",
      "discriminator training cost for gan batch  31  is:  0.689559\n",
      "generator training accuracy for gan batch  31  is:  0.0\n",
      "generator training cost for gan batch  31  is:  0.857967\n",
      "gan batch:  32\n",
      "generated during training batch  32 :\n",
      "<SOR>eiee eeeeuee eeeeeeeeeee eeeeeee eeeee eeeeeeeee eeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeee eeeeee e eeee eeeeeeeee eeeeeeeeeeeeeeeeeeeeeee eeeeeeee eeeeeeeee eeeeeeeeeeeueeeeee eeee eeeee eeeeee eeeeeeeeeuee ee eeeee ee eeeeeeeeeeee eeeee eeeeeeeueeee eeeeeeeeeeeeee eeeeeeeeeeeeeee eeeee eeeeeeeeeeeeeeeeee eeeaeee e eeeee \n",
      "<SOR> eeeeee ee eeeeeeeeeee eeeeee eeeeeeenee eeeeeeeeeeee eeeeeeeeeeeeeeeeeieeeeeeeeeee eee eeee ee eeee e eeeeeeeeee e ee eee eeeeeeueee ee eeeeeee eeeeeeeeee eeeeeeeeeeee eeeeeeeeeeeeeee e eeeeeeeeeeeueue eeeeee eee e eeeieeeeee eeee eeeeee e eeeeeeeeeeeeee eeseeeeeeeeeeee eeeee eeeeee eeee eeee eeeeeeeee eeeeeeeeeeee.eeeeeee\n",
      "<SOR>e eeeee eeeeee eee eeeeeeeeeee eeee e eeeeeeeeeeeeeeeeeeeeee eee eeeeeee eeeeeeeeeeee eeeeeeeeeeeeeeeee eeeeee eeeeeeeeeeeeeeeeeeee eeeee eee eeee ee eeeeee eeeeeeeeeee eeeeeeeeeeeeeeeeee eeeeeeeeieeeeeeeeeeeeeee e eeeeeeeeeeee eeeeeeee eeeue eeeeeeeee eeee eeeeeeee ee eeeeeeeeeeeeeeee eeeeeeeeeeee eeeeee eeeeeeueeeeeeeeeee\n",
      "<SOR> eeeseeeeeeeeeeee eeeeeeeeeeeeeeeeeueeee eeeeeeeeeeeeee eee eeeeeeee eee eeeeeeeee eeeeeeeeee eeeeeeeeaeeee eeeeeeeeee eeeeeeeeeeeeeeeeeee eeeeeeeeeeseeeeeee eee eeeeeeee eeeeeeeee eee eeeeeeeeeee eee eeeeeeeeeee eeeeeee eeeeeeeeeeee e eeeeeeeeeeeee eeeeeeeeeeeeeee eeeeee eeeeeeee ee eeeeeeee eeeeeeeeeeeeeeeeee eeeeeeeee ee\n",
      "<SOR>  eeeeueeee eeeeeeeeee eeeeeeee eeeeeeeee eeeeeee eeeeeeeeueeee eeeeeeee eeeeeeeeee eeee eeeeeeee eeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeee ee eeeeueee eeee eeeueeeeeeeeeeeeeee eee eeeeeeeee eeeeeeee eeeeeeee e eeeeee eeeueee eeeeeeeeee eeeeeee eeeee eeeeeeeeee eeeueeeeeee eeeeeeeeue eeeeeeeeueeeee ee eeeeeeeeee eeeeeeee\n",
      "gan batch:  32  has  64  real reviews and  64  artificial reviews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator training accuracy for gan batch  32  is:  0.5\n",
      "discriminator training cost for gan batch  32  is:  0.690277\n",
      "generator training accuracy for gan batch  32  is:  0.0\n",
      "generator training cost for gan batch  32  is:  0.827965\n",
      "gan batch:  33\n",
      "generated during training batch  33 :\n",
      "<SOR> eeeeeeeeeee eeeeeeeeee eeeeee eeeeee eeeeeeeeueeeeeeeeee eeeeeeee eeeeeee ee.e eeeeeeeeeee eeeeeeeeeeee eeeue eeeeeeeeee eeeeeeeeeeeeeeeeeee eeeeeeeeeee eeeeeese eee eeeeeeee ee eeeeeeeeee ee eeeeee.eeeene eeee eeeeeeeee eeeeeeeee eeeeee eee eeeeeeeueeeeee eeeeeeeee eeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeee eeeeeee eeeeee eeeee\n",
      "<SOR>ieee eeeeeeeeeee eeeneeee eeeeee eeeeeeeeeeeeeeeeeeeeeueeeee eeeeeeeeeeeeeeeeee eueeeeeeeeeeeue eeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeee eeueeee eeeeeeeee eeee eeeeeeeeeeeeeee eeeeeeenee eeeeeeeeeeeeeeeeeeeee eeeeueeeee eeee eeee eeee eee ee eeueeeeeeee eeeueee eueeee eeueeeeee eeieeeeeeeee eeeeeeeee eeeeee eeee eeeeee eee e\n",
      "<SOR>e eeeeeeeeeee eeeeeeee eeeeeuee eeeese eeeeeeeeee eeueee eeeeeeeeeee eeeee ee eeeeeeeeeeeeee eeeeeee eeeaeueee eeeeeeeeeeeeeeee eeeeeeeee eee eeeeee eeeeeeeeeeeeeee eeeuee eeeeeeueeeee eeee eeeeeeee eeeeeeeeeeeeeeeee eeueeeeeee eeeeeeeueeeeeee ee eeeeeeeeeeeeeeeeeeee eeeeeeeeeee eeeeee eeeee eeeeee eeeeeeeeeeeeeeeeeeeeee ee\n",
      "<SOR>t eeeeeeeee eeueeee eeeeeeeeeeee eeeee eeeeee eeeeeeeeeeeee eee eeeeeeeeueeeeee eeeeeeeeee eee eeeeeeeeeeeee. eeee eeeee eeeeeeeeeeee eeeeeeeeeeeeeee eeeeue eeeeeeu eeeeeleeeeeeeee eeeeeeeeeeeueeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeee eee eeeeueeleeeeee eeeeeee ee ee eeeeeeeeee eeeeee eeeee eeeee eeeeeeeeeeeeeieeeeeee eeeeeeeee e\n",
      "<SOR>e eeeeeeeeeleeee eeeeeeeeeeeeeeeeeee ee eeeeee eeue eueeeeee eeeee e eeeeee e eee eeeeeeee eee eeeeeeeeeeeeeeeee eeeeeeeeeeeee eeeeeeee eeee eeeeeeueee eeeeele eeeeee eeeeeeeeee eeeeeeee ee eee eeeeee eeeeeeee eeeeese ee ee eeeueueeeee eeueeee e eeeueeeeeee eeeeeeeeeee eee eeeeeeueee eee eeeeeueeeeeeeeeeeeeeeeeee eeeee eee \n",
      "gan batch:  33  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  33  is:  0.5\n",
      "discriminator training cost for gan batch  33  is:  0.689773\n",
      "generator training accuracy for gan batch  33  is:  0.0\n",
      "generator training cost for gan batch  33  is:  0.820003\n",
      "gan batch:  34\n",
      "generated during training batch  34 :\n",
      "<SOR> eseeeeeeeeeeee eeeeeeee eeeeeee eeeeeeeeeeee eeee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeee eeeeeneeeeee eeeeeeeeeee eee eeeeeeeeeee eee eeeeeeeeeeeeee ee eeeeeeee eeeeeeeeeeeeeeee eeeeeee eeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeueeee eeeeeeeeeeeeeeeeeeeeeee eeee eeeeeeeeeeeee ee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee ee\n",
      "<SOR>e eeeeeeeeu.eeeeeeeeeeeeeeeeueeee eeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeee eeeeeeneeee eeeeeeeeeeeneeeeeee e eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeueeeeeeeee eeeeeeeeeeeeeeeeee eeeeeeeee eee eeeeeeeeeeee eeeeeeueeeeee.eeeeeeeeeeeeeeeeee eeeeeee eee eeeeeee e eeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eee eeeeeee\n",
      "<SOR>e eeeeee eeeeee eeeeeeeeeeeeeeeee eeeee eeeeeeeeeeeeeeeeeeeeeeeeeee eeee eeeeeeeeeeeeee eeeeee  eee eeeee eeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieee eeeeeeueeeeeeeee eeeeeeeeeeeeeeeeeeeeeeee eeeeeeee eeneeeeee eeee eeeeeeeeeeeeeeeeeeeueeee ee eeeeeeeeeeeeeeeeeeeeeeeeeeueeeueeeeee eeeeeeeeeee eeeeeeeeeeen\n",
      "<SOR>iee.eeeeeeee eeeeeeeeeeeeeee eeeeeeeeeeeeee eeeeeeeeseeeeeee eeeeeeeeeeee eeeeeeeeeeeeeeee eeeeee eeeeee eeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeee ee eeeeeeeeeeeeeee eeeeeeee eueeeeee eeeeeee eeeeeeeeeeeeeeeee eeeeee e eeeeeeeeeeeeeeeeleee eee eeeeeeeeeeeeeeeeeee e eeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeee eeeeeee eeeeeee eeeeeeeee\n",
      "<SOR>o eee eeeeeeeeeeeeeeeeeeeeeeueeeeeeeeeeeeeeeeeeeeee eeeeeeeee eeeeeeeeeeeeeeeeeeeeeneeeee eeeeeeeeeee eeeeeeeeeeee eeeeeee eeeeeeeeeesee eeee eeeeeeee eeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeee eeeeeeeee eee eeeeeuee eeeeeeeeue eeeeeeeeeeeeeleeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeee eeeeeee\n",
      "gan batch:  34  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  34  is:  0.5\n",
      "discriminator training cost for gan batch  34  is:  0.694019\n",
      "generator training accuracy for gan batch  34  is:  0.0\n",
      "generator training cost for gan batch  34  is:  0.813909\n",
      "gan batch:  35\n",
      "generated during training batch  35 :\n",
      "<SOR> eee eeeeeeeeeeeeeeeeeeueeee eeeeee eeee eeeeeeeeeeeeeeeeeeeeeeeeeeee e eeeeeee ee eeeeeieeeeeeeeeeeeeee eeeeeeeeeeeee eeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeueee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeee eeeeeeeeneeeeeeeeeeeeeeee eeeeeeeeeeeeeeeee eeeeeeeeeee e eeeeeeieeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeee\n",
      "<SOR>e eeeeeeeeeeeeeeeeeee eeeeeeee eeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeieeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeee e eeeeeeeeeee eeeeeeeeee eneueeeeee eeeeeaeee eeeeeeeeeueeee eeeeeeeeeeeeeee eeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeueeeeeee eeeeeeeeeeeee eeeee eeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>ae eeeeeeeeee eee eeeeeeeeeeeeeeee eeeeeeeeeeeeeee eeeeeeeeeeeeeeneeeeeeeeeeeeeeeeee eeeeee eeeeeee eeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeueeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeee eeeeeeeeeeeeeeeeieee eueeeeeeee eeeeeeeeee eeeeee eeeneeeeeeeeeee eee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeu\n",
      "<SOR>ue eee eeeeee eeeeeeeeeeeeeeeeueeeeeeeeee ee eeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeneeeeeeeeeeeueeeeee eeeeeeeee eeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeee ee eeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeee eeeeieeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>  eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeee eeeee eeeeeeeeeeeeeeeeeueeeeeeeeeeeeieeeeeeeeeeeeeueeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeueeeeeee eeeeeeeeeeeeeeeie eeeeeeee eeeeeeeeeeeeueeeeeeeeeeeeee eeeeeeaeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeueeeeeeee eeeeee eeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  35  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  35  is:  0.5\n",
      "discriminator training cost for gan batch  35  is:  0.692185\n",
      "generator training accuracy for gan batch  35  is:  0.0\n",
      "generator training cost for gan batch  35  is:  0.735293\n",
      "gan batch:  36\n",
      "generated during training batch  36 :\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeueeeeeeeeeneeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeenee eeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeee eeeeeneeeee eeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeee eeeeeeeeeeeeeeeee eeeeeee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeee eeee eeeeeeee eeeeese eeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeee eeeeeeeeeeneee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeee e eeeneee eeeeeeeneee\n",
      "<SOR> e eee eeeeee eee eeeeuee eeeeeeeeeueeeeeieeee eeeeeeeeeeeeee eeeeeeeeeeeee eeeeeeeeeeeeeeneeeeeeeeeeeeeeeeueeeeeeeeeieeeeeeeeeeeeeeee.eeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeee eeueeeeeee e eeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeee eeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeee eeeeeeeeeeeeeeeee\n",
      "<SOR>ieeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.e eeeeee eeeeeeeeeeeeeee.eeeeeeee eeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeee eeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeee eeeeeeneeeeeeeeeeeeee eeeeeeeeeeeneeeeeeeee ene eeeeeeeeeeeeeeeeee eeeeeeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeue eeee eeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeneeeee eeeeeeeeeeeeeeeeeeeeee eeeee eeeeeeeeie eeeeeee eeeeeeeeeeene eeeeeeeeeeeeeeee e eeueee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  36  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  36  is:  0.5\n",
      "discriminator training cost for gan batch  36  is:  0.694524\n",
      "generator training accuracy for gan batch  36  is:  0.0\n",
      "generator training cost for gan batch  36  is:  0.702003\n",
      "gan batch:  37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated during training batch  37 :\n",
      "<SOR>ieeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeee eeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>oteeeeeeeeeeeeeeeee eeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeueeeeeeeeeeieeeeeeeeeeen eeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeee.ee\n",
      "<SOR>ieeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeneeeeeeeeeeueeeeeeeeeeeeeeeeee eeeeeeeeee eeeeeeeeeeeeee.eeeeeeeeeeaeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeieeeeeeeeeeee eeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeele eeeeeeeeeee eeueeeeeeee eeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>edeeeeeeeeeeeeeeeeee eeeneeeeeee eeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeneeeeeeeeeeeeeeeneeeeeeeee eeeneeeeeeeeeeeeeee\n",
      "gan batch:  37  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  37  is:  0.5\n",
      "discriminator training cost for gan batch  37  is:  0.693174\n",
      "generator training accuracy for gan batch  37  is:  0.0\n",
      "generator training cost for gan batch  37  is:  0.698717\n",
      "gan batch:  38\n",
      "generated during training batch  38 :\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>eneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeee.eeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee e eeeeeeeee eeeeeneeeeeeeeee\n",
      "<SOR>eeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeueeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeee eneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>eneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeenleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeieeeeeeeee eeeeeeeeeeee.eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeneeeeeeeeeeeeueeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  38  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  38  is:  0.5\n",
      "discriminator training cost for gan batch  38  is:  0.693163\n",
      "generator training accuracy for gan batch  38  is:  0.0\n",
      "generator training cost for gan batch  38  is:  0.697091\n",
      "gan batch:  39\n",
      "generated during training batch  39 :\n",
      "<SOR>eieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeee\n",
      "<SOR>y eeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeleeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeieeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>ieeeeeeeeeeeeeeeeeeeeeeeeeieeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.leeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeueeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>) eeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeele.eeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeel\n",
      "<SOR>e.eeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeueaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  39  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  39  is:  0.5\n",
      "discriminator training cost for gan batch  39  is:  0.693155\n",
      "generator training accuracy for gan batch  39  is:  0.0\n",
      "generator training cost for gan batch  39  is:  0.695584\n",
      "gan batch:  40\n",
      "generated during training batch  40 :\n",
      "<SOR>eieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeenieeleeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeee\n",
      "<SOR>ieeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeelee\n",
      "<SOR> eeeeeeeeeeeeeeeeeleeeeeeeleeeeeeeeeleeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>ieeeeeeeleeleeeeeeeeeeee.eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeleeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeelaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  40  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  40  is:  0.5\n",
      "discriminator training cost for gan batch  40  is:  0.69315\n",
      "generator training accuracy for gan batch  40  is:  0.0\n",
      "generator training cost for gan batch  40  is:  0.694197\n",
      "gan batch:  41\n",
      "generated during training batch  41 :\n",
      "<SOR>sieeeeeeeeeeeeeeeeeleeeeeieeeeeeeeeeeee eeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeaeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeleeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>aeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeele eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeee\n",
      "<SOR>ieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>e eeeeeeeeeleee.eeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeleeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeee\n",
      "<SOR>ieeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeaeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeelelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  41  has  64  real reviews and  64  artificial reviews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator training accuracy for gan batch  41  is:  0.5\n",
      "discriminator training cost for gan batch  41  is:  0.693148\n",
      "generator training accuracy for gan batch  41  is:  1.0\n",
      "generator training cost for gan batch  41  is:  0.692927\n",
      "gan batch:  42\n",
      "generated during training batch  42 :\n",
      "<SOR> eeeneeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeealeeeleeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeueeeeeelee e\n",
      "<SOR> eieeeeeeeeeleeeeeeeeeeeeleee.eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeleeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeleeeeeeeeeeee.eeeeleeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeleeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeeee\n",
      "<SOR> eeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeeieeeeeeeeeeleeee.eeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeneeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeleeeeeeee\n",
      "<SOR>ieeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleee\n",
      "gan batch:  42  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  42  is:  0.5\n",
      "discriminator training cost for gan batch  42  is:  0.693147\n",
      "generator training accuracy for gan batch  42  is:  1.0\n",
      "generator training cost for gan batch  42  is:  0.691776\n",
      "gan batch:  43\n",
      "generated during training batch  43 :\n",
      "<SOR> eeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeieeeeleeneeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeleeeeieeeeeeeeeelee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieleeeeeleeaeeeaeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeleeeeeeeeeleealeeeieeeeeeeeeeeeeeeleeeeeeeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeleeeeeeeeeeleaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeleaeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeaeeeeleeeeeeeeeeeeeeeieeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee.eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeaeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeleeeeeeeeeleeeleeleeeeeeeeeeeeeeeneeeeleeeeeeeeeeeeeeeleeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  43  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  43  is:  0.5\n",
      "discriminator training cost for gan batch  43  is:  0.693148\n",
      "generator training accuracy for gan batch  43  is:  1.0\n",
      "generator training cost for gan batch  43  is:  0.690741\n",
      "gan batch:  44\n",
      "generated during training batch  44 :\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleueeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeleeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>eaeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeleeeeeeeeeeeeeeeeeeeeeeeleeeeleeeeeeee\n",
      "<SOR>ueeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeleeeieeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>ieeeeeeeeeeeaeeleeeeeleeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeileeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeleeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleaeeneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  44  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  44  is:  0.5\n",
      "discriminator training cost for gan batch  44  is:  0.69315\n",
      "generator training accuracy for gan batch  44  is:  1.0\n",
      "generator training cost for gan batch  44  is:  0.689819\n",
      "gan batch:  45\n",
      "generated during training batch  45 :\n",
      "<SOR>~.eeeeeeleeeleeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeleeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeel\n",
      "<SOR>eeeeeleeeeeeeeeeeeaeeeeeeleeeeeeeeeeeeeeeeeeeleeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeleeeeeeeeeeeleeeeeeeeeeelleeeeeeeeeeeeeeee\n",
      "<SOR>eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeleaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeleeeeeeeeieeeeleeleeeleeeeeeeieeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeleeleeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeleeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeaeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>eeeeaeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeieeeeeelleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeieeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  45  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  45  is:  0.5\n",
      "discriminator training cost for gan batch  45  is:  0.693153\n",
      "generator training accuracy for gan batch  45  is:  1.0\n",
      "generator training cost for gan batch  45  is:  0.689008\n",
      "gan batch:  46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated during training batch  46 :\n",
      "<SOR> eeeeeeeeeeeeeleeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeelleeeeeeeeeeeeeeleeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleleeeeeeeee\n",
      "<SOR> eeeeeeieeeeeeeeeeeeeeeeeleeeeleeeeeeeeeeleeeeeeeeeeeeeeeeeeeleeeeeeeeleeeeeeeneeeeleeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeleeeeeeeleeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeleeeleeeeeeleeeeeeeeleeeeeeeeeeleeeeeeeeleeeeeleeeeleeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeelleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeneeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeleeeeeeeeeleeleeeeeeeeeaeeeeeeeeeeleeeeee eeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeaeeeeeleeeeeeeleeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeleeeeeeeeeeeeeeeeeleeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleelee\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeleeeeeeeeeeeeeaeeeeleeeeeeeeeeeeeeeeeeeelleeaeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeelee eeeeeeeeeeeeeeeeeeeeeeeeeieeeeeleeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeleeeeeeeeee\n",
      "gan batch:  46  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  46  is:  0.5\n",
      "discriminator training cost for gan batch  46  is:  0.693156\n",
      "generator training accuracy for gan batch  46  is:  1.0\n",
      "generator training cost for gan batch  46  is:  0.688304\n",
      "gan batch:  47\n",
      "generated during training batch  47 :\n",
      "<SOR>e eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeieeeeeeeeeeeeeeeeeeeeeeeelaeeeeeeeeeeeeleeeleeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeleeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeleeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeleeeieeeeeeeeeeeeeeeeeeeeeleelieeeeeeeieeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeleeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eneeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleneeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeleieeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeleeeeeeeeleeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "<SOR>eaeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeleeeeeeeeleeeeeeeeeleeeeeeeeeeeeeeeeeleeeeeeeeeeeeleeeeeeleeeeeleeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeaeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeee\n",
      "<SOR> eeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeleeeeeeeleeeeleeeeeeeeeeeeeeeeeleeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeelleeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeleeeaeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeee\n",
      "gan batch:  47  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  47  is:  0.5\n",
      "discriminator training cost for gan batch  47  is:  0.693159\n",
      "generator training accuracy for gan batch  47  is:  1.0\n",
      "generator training cost for gan batch  47  is:  0.687705\n",
      "gan batch:  48\n",
      "generated during training batch  48 :\n",
      "<SOR> eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeleeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeleeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeleeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeelleeeeeeeeeeaeeeeeeeleeeeeeeeeeaeeeeeeeeee\n",
      "<SOR>eeeeeeeeeeeleeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeleeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeleeelleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeleeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeee\n",
      "<SOR> eeeeleeeeeeeeeeeeeeeeeeeeeeeeealeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeealeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeeee.eeeeeeeeeleleeeeeeeeeeeeeeeeeeeeleeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeleeeeeeeleeeeeeeeee\n",
      "<SOR>eeeleeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeelleeeleeeleeeeeieeeeeeeeeeeeleeeeeeeeeeeeeaeeeeieeeeeeeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeele\n",
      "<SOR>eieeleeeeeeeeeeleeeeleeeeeeeeeeeeeeleeeeeeeeeeealeeeeeeeeeeeeeeeaeeeeeeeeeeeleeeeeeeeeeeeeeeeeleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeleeeeeleeeeeeeeeeeeeleeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeleeeeeeeeeeee\n",
      "gan batch:  48  has  64  real reviews and  64  artificial reviews.\n",
      "discriminator training accuracy for gan batch  48  is:  0.5\n",
      "discriminator training cost for gan batch  48  is:  0.693162\n",
      "generator training accuracy for gan batch  48  is:  1.0\n",
      "generator training cost for gan batch  48  is:  0.687205\n",
      "gan batch:  49\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "#model_params = dict(V=len(words_to_ids.keys()), H=1024, softmax_ns=len(words_to_ids.keys()), num_layers=2)\n",
    "model_params = dict(V=len(words_to_ids.keys()), H=1024, softmax_ns=len(words_to_ids.keys()), num_layers=2)#low numbers for dev\n",
    "#trained_filename_real = run_training(train_ids_real, test_ids_real_training_eval, tf_savedir = \"/tmp/defense_model/real\", model_params=model_params, max_time=150, batch_size=128, learning_rate=0.002, num_epochs=20)\n",
    "#trained_filename_artificial = run_training(train_ids_artificial, test_ids_artificial_training_eval, tf_savedir = \"/tmp/defense_model/artificial\", model_params=model_params, max_time=150, batch_size=128, learning_rate=0.002, num_epochs=20)\n",
    "#run_training(train_ids, test_ids, words_to_ids, ids_to_words, tf_savedir, model_params, max_time=100, batch_size=256, learning_rate=0.002, num_epochs=20)\n",
    "trained_filename = run_training(train_ids_real[:20000], test_ids_real_training_eval[:1000000], words_to_ids, ids_to_words, tf_savedir = \"/tmp/gan_model/practice\", model_params=model_params, max_time=150, batch_size=64, learning_rate=0.004, num_epochs=1)#UPDATE FOR ACTUAL RUN\n",
    "#trained_filename_artificial = run_training(train_ids_artificial, test_ids_artificial_training_eval[:1000000], tf_savedir = \"/tmp/defense_model/artificial\", model_params=model_params, max_time=150, batch_size=128, learning_rate=0.002, num_epochs=20)#UPDATE FOR ACTUAL RUN\n",
    "end_training = time.time()\n",
    "print(\"overall training took \" + str(end_training-start_training) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### UPDATED!!!\n",
    "#save both RNNs for later use\n",
    "save_command_1  = \"gsutil cp -r \" + trained_filename_real[0:trained_filename_real.rfind(\"/\")] + \" gs://w266_final_project_kk/defense_baseline/real/\" + str(int(np.floor(time.time())))\n",
    "save_command_2  = \"gsutil cp -r \" + trained_filename_artificial[0:trained_filename_artificial.rfind(\"/\")] + \" gs://w266_final_project_kk/defense_baseline/artificial/\" + str(int(np.floor(time.time())))\n",
    "#save_command_1  = \"gsutil cp -r \" + trained_filename_real[0:trained_filename_real.rfind(\"/\")] + \" gs://w266_final_project_kk/practice_run/defense_real/\" + str(int(np.floor(time.time())))\n",
    "#save_command_2  = \"gsutil cp -r \" + trained_filename_artificial[0:trained_filename_artificial.rfind(\"/\")] + \" gs://w266_final_project_kk/practice_run/defense_artificial/\" + str(int(np.floor(time.time())))\n",
    "os.system(save_command_1)\n",
    "os.system(save_command_2)\n",
    "### UPDATED!!!\n",
    "\n",
    "#generate examples from each GAN out of curiosity\n",
    "start_sampling = time.time()\n",
    "generate_text(trained_filename, model_params, words_to_ids, ids_to_words)\n",
    "#generate_text(trained_filename_artificial, model_params, words_to_ids, ids_to_words)\n",
    "end_sampling = time.time()\n",
    "print(\"character sampling took \" + str(end_sampling-start_sampling) + \" seconds\")\n",
    "\n",
    "#\n",
    "\n",
    "#first feed the real reviews into each RNN and get the softmax probability of each character\n",
    "#get the classification for real reviews by forming an average negative log-likelihood ratio for each review\n",
    "start_scoring = time.time()\n",
    "test_likelihoods_real_from_real = get_char_probs(trained_filename_real, model_params, test_ids_real[:1000])\n",
    "test_likelihoods_real_from_artificial = get_char_probs(trained_filename_artificial, model_params, test_ids_real[:1000])\n",
    "predictions_real = neg_log_lik_ratio(test_likelihoods_real_from_real, test_likelihoods_real_from_artificial)\n",
    "#negative_log_lik_ratios = -1*(np.log(np.divide(test_likelihoods_real_from_real, test_likelihoods_real_from_artificial)))\n",
    "#predictor = \n",
    "\n",
    "#next feed the generated reviews into each RNN and get the softmax probability of each character\n",
    "#get the classification for generated reviews by forming an average negative log-likelihood ratio for each review\n",
    "test_likelihoods_artificial_from_real = get_char_probs(trained_filename_real, model_params, test_ids_artificial[:1000])\n",
    "test_likelihoods_artificial_from_artificial = get_char_probs(trained_filename_artificial, model_params, test_ids_artificial[:1000])\n",
    "predictions_artificial = neg_log_lik_ratio(test_likelihoods_artificial_from_real, test_likelihoods_artificial_from_artificial)\n",
    "end_scoring = time.time()\n",
    "print(\"review scoring took \" + str(end_scoring-start_scoring) + \" seconds\")\n",
    "\n",
    "### UPDATED!!!\n",
    "predictions_real = np.array(predictions_real)\n",
    "predictions_artificial = np.array(predictions_artificial)\n",
    "np.savetxt(\"predictions_real.csv\", predictions_real, delimiter=\",\")\n",
    "np.savetxt(\"predictions_artificial.csv\", predictions_artificial, delimiter=\",\")\n",
    "os.system(\"gsutil cp predictions_real.csv gs://w266_final_project_kk/defense_baseline/predictions_real/\")\n",
    "os.system(\"gsutil cp predictions_artificial.csv gs://w266_final_project_kk/defense_baseline/predictions_artificial/\")\n",
    "#os.system(\"gsutil cp predictions_real.csv gs://w266_final_project_kk/practice_run/defense_predictions_real/\")\n",
    "#os.system(\"gsutil cp predictions_artificial.csv gs://w266_final_project_kk/practice_run/defense_predictions_artificial/\")\n",
    "### UPDATED!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
